

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 3. Knowledge Representation &#8212; Artificial Intelligence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap3';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Chapter 4. Machine Learning" href="chap4.html" />
    <link rel="prev" title="Chapter 2. Intelligent Agents" href="chap2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Table of Contents                              
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preface.html">Preface</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chap1.html">Chapter 1. History of AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap2.html">Chapter 2. Intelligent Agents</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Chapter 3. Knowledge Representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap4.html">Chapter 4. Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap5.html">Chapter 5. Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap6.html">Chapter 6. Computer Vision</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lab</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lab1.html">Lab 1: Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab2.html">Lab 2: Supervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab3.html">Lab 3: Multivariate Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab4.html">Lab 4: Dimensionality Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab5.html">Lab 5: Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab6.html">Lab 6: Nonparametric Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab7.html">Lab 7: Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab8.html">Lab 8: Linear Discrimination</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab9.html">Lab 9: Neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab10.html">Lab 10: Local Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab11.html">Lab 11: Kernel Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab12.html">Lab 12: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab13.html">Lab 13: Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab14.html">Lab 14: Natural Language Processing</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fchap3.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap3.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 3. Knowledge Representation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#propositional-logic">Propositional logic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-components">Basic Components</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logical-connectives">Logical Connectives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#truth-tables">Truth Tables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations">Limitations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-order-logic">First-order logic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#core-elements-of-first-order-logic">Core Elements of First-order Logic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#syntax-and-semantics">Syntax and Semantics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-of-first-order-logic">Applications of First-order Logic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Limitations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-first-order-logic">Tools for First-order Logic</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-networks">Semantic networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#core-elements">Core Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-characteristics">Key Characteristics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Limitations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evolution">Evolution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-and-scripts">Frames and scripts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#frames">Frames</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scripts">Scripts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-vs-scripts">Frames vs. Scripts</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ontologies-and-knowledge-graphs">Ontologies and knowledge graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ontologies">Ontologies</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#characteristics">Characteristics:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#purpose">Purpose:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-graphs">Knowledge Graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Characteristics:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Purpose:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intersections-and-complementary-use">Intersections and Complementary Use</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Applications:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rule-based-systems">Rule-based systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#components-of-rule-based-systems">Components of Rule-Based Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Characteristics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-limitations">Challenges and Limitations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-networks">Bayesian networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-representation-in-neural-networks">Knowledge representation in neural networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#representing-knowledge-in-neural-networks">Representing Knowledge in Neural Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-considerations">Challenges and Considerations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-representation-and-reasoning-in-natural-language-processing">Knowledge representation and reasoning in natural language processing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-representation">Knowledge Representation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reasoning">Reasoning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-sense-reasoning-and-knowledge-bases">Common-sense reasoning and knowledge bases</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-sense-reasoning">Common-Sense Reasoning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definition">Definition</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-in-ai">Challenges in AI</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-bases">Knowledge Bases</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Definition</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">Challenges</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connecting-reasoning-and-knowledge-bases">Connecting Reasoning and Knowledge Bases</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-3-knowledge-representation">
<h1>Chapter 3. Knowledge Representation<a class="headerlink" href="#chapter-3-knowledge-representation" title="Permalink to this heading">#</a></h1>
<blockquote class="epigraph">
<div><p><em>“Do the difficult things while they are easy and do the great things while they are small. A journey of a thousand miles must begin with a single step.”</em>
– Lao Tzu</p>
</div></blockquote>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">Knowledge Representation and Reasoning at Wikipedia</a></p></li>
</ul>
</div>
<section id="propositional-logic">
<h2>Propositional logic<a class="headerlink" href="#propositional-logic" title="Permalink to this heading">#</a></h2>
<p>Propositional logic, also known as propositional calculus or Boolean logic, is a branch of logic that deals with propositions and their interrelations. It’s the simplest form of logic where the statements are made up of propositions, which can either be true or false, and are combined using logical connectives. The fundamental aspects and characteristics of propositional logic are useful in various fields, including computer science, mathematics, and philosophy.</p>
<section id="basic-components">
<h3>Basic Components<a class="headerlink" href="#basic-components" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Propositions</strong>: These are declarative statements that are either true or false but not both. For example, “It is raining” is a proposition because it can either be true or false.</p></li>
<li><p><strong>Atomic Propositions</strong>: These are propositions that contain no logical connectives; they cannot be broken down into simpler propositions.</p></li>
<li><p><strong>Compound Propositions</strong>: These are formed by combining atomic propositions using logical connectives. Examples include conjunctions (AND), disjunctions (OR), negations (NOT), implications (IF…THEN), and biconditionals (IF AND ONLY IF).</p></li>
</ol>
</section>
<section id="logical-connectives">
<h3>Logical Connectives<a class="headerlink" href="#logical-connectives" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Negation (¬ or ~)</strong>: This inverts the truth value of a proposition. For example, if P is “It is raining,” ¬P (not P) means “It is not raining.”</p></li>
<li><p><strong>Conjunction (∧)</strong>: This is true if and only if both propositions it connects are true. P ∧ Q is true only if both P and Q are true.</p></li>
<li><p><strong>Disjunction (∨)</strong>: This is true if at least one of the propositions it connects is true. P ∨ Q is true if P is true, or Q is true, or both are true.</p></li>
<li><p><strong>Implication (→)</strong>: This represents a conditional statement. P → Q (P implies Q) is true if either Q is true or P is false. It is false only if P is true and Q is false.</p></li>
<li><p><strong>Biconditional (↔)</strong>: This is true if both propositions have the same truth value. P ↔ Q is true if both P and Q are true, or both P and Q are false.</p></li>
</ul>
</section>
<section id="truth-tables">
<h3>Truth Tables<a class="headerlink" href="#truth-tables" title="Permalink to this heading">#</a></h3>
<p>Truth tables are a systematic way to explore and represent the truth values of propositions based on the truth values of their atomic components. Each row of a truth table corresponds to a possible combination of truth values for the component propositions, and it shows the resulting truth value of the compound proposition for those values.</p>
</section>
<section id="applications">
<h3>Applications<a class="headerlink" href="#applications" title="Permalink to this heading">#</a></h3>
<p>Propositional logic finds applications in various disciplines:</p>
<ul class="simple">
<li><p><strong>Computer Science</strong>: It is foundational for understanding computation, designing circuits, and developing software, especially in areas related to logical reasoning, such as artificial intelligence and databases.</p></li>
<li><p><strong>Mathematics</strong>: Propositional logic is used to prove theorems and in the study of mathematical proof.</p></li>
<li><p><strong>Philosophy</strong>: It helps in analyzing philosophical arguments and in the formalization of philosophical theories.</p></li>
<li><p><strong>Linguistics</strong>: Understanding the logical structure of language and sentences.</p></li>
</ul>
</section>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this heading">#</a></h3>
<p>While powerful, propositional logic has limitations. It does not allow for the expression of propositions involving quantifiers (like “all” or “some”) or the relationships between objects beyond their logical connections. Predicate logic extends propositional logic to address these limitations by dealing with predicates and quantifiers.</p>
<p>Overall, propositional logic is a fundamental part of logic and a crucial tool in various scientific and philosophical investigations.</p>
</section>
</section>
<section id="first-order-logic">
<h2>First-order logic<a class="headerlink" href="#first-order-logic" title="Permalink to this heading">#</a></h2>
<p>First-order logic (FOL), also known as predicate logic or first-order predicate calculus, serves as a powerful framework for formalizing statements in mathematics, science, and computer science. It extends propositional logic by incorporating quantifiers and predicates, which allows for the expression and manipulation of more complex statements about objects and their relationships.</p>
<section id="core-elements-of-first-order-logic">
<h3>Core Elements of First-order Logic<a class="headerlink" href="#core-elements-of-first-order-logic" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Predicates</strong>: Predicates express properties of objects or the relationship between objects. For example, <code class="docutils literal notranslate"><span class="pre">IsBlue(x)</span></code> could represent that object x is blue, while <code class="docutils literal notranslate"><span class="pre">Loves(x,</span> <span class="pre">y)</span></code> might represent that x loves y.</p></li>
<li><p><strong>Quantifiers</strong>: There are two primary quantifiers:<br />
a. Universal quantifier (∀) - expresses that some property holds for all elements in a domain. E.g., <code class="docutils literal notranslate"><span class="pre">∀x</span> <span class="pre">IsBlue(x)</span></code> means “everything is blue”.<br />
b. Existential quantifier (∃) - indicates that there exists at least one element in the domain for which the property holds. E.g., <code class="docutils literal notranslate"><span class="pre">∃x</span> <span class="pre">IsBlue(x)</span></code> means “there exists something that is blue”.</p></li>
<li><p><strong>Functions</strong>: Functions map objects to other objects, similar to mathematical functions. For instance, <code class="docutils literal notranslate"><span class="pre">FatherOf(x)</span></code> could denote the father of x.</p></li>
<li><p><strong>Constants</strong>: These represent specific objects in the domain of discourse. For example, <code class="docutils literal notranslate"><span class="pre">Earth</span></code> could be a constant denoting the planet Earth.</p></li>
<li><p><strong>Variables</strong>: Variables are placeholders for objects in the domain. For example, in <code class="docutils literal notranslate"><span class="pre">IsBlue(x)</span></code>, x is a variable that can represent any object.</p></li>
<li><p><strong>Logical Connectives</strong>: These include <code class="docutils literal notranslate"><span class="pre">and</span></code> (∧), <code class="docutils literal notranslate"><span class="pre">or</span></code> (∨), <code class="docutils literal notranslate"><span class="pre">not</span></code> (¬), <code class="docutils literal notranslate"><span class="pre">implies</span></code> (→), and <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">and</span> <span class="pre">only</span> <span class="pre">if</span></code> (↔), which are used to build more complex expressions from simpler ones.</p></li>
</ol>
</section>
<section id="syntax-and-semantics">
<h3>Syntax and Semantics<a class="headerlink" href="#syntax-and-semantics" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Syntax</strong> refers to the formal structure of expressions in first-order logic, including how complex sentences are constructed from atomic components like predicates, quantifiers, and logical connectives.</p></li>
<li><p><strong>Semantics</strong> deals with the meaning of the expressions, including how to interpret them in a domain of discourse and how to evaluate their truth or falsity.</p></li>
</ul>
</section>
<section id="applications-of-first-order-logic">
<h3>Applications of First-order Logic<a class="headerlink" href="#applications-of-first-order-logic" title="Permalink to this heading">#</a></h3>
<p>First-order logic is foundational in various areas:</p>
<ul class="simple">
<li><p><strong>Mathematics</strong>: For formal proofs and definitions.</p></li>
<li><p><strong>Computer Science</strong>: In programming language semantics, database query languages (e.g., SQL), and artificial intelligence for knowledge representation and reasoning.</p></li>
<li><p><strong>Philosophy</strong>: For formal analysis of arguments and philosophical reasoning.</p></li>
</ul>
</section>
<section id="id1">
<h3>Limitations<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>While powerful, first-order logic has its limitations. It cannot express certain types of propositions, such as those requiring second-order logic (where quantification over sets or properties, rather than individuals, is allowed). Also, first-order logic might not be decidable for certain theories, meaning there may not be an algorithm that can determine the truth of every statement within those theories.</p>
</section>
<section id="tools-for-first-order-logic">
<h3>Tools for First-order Logic<a class="headerlink" href="#tools-for-first-order-logic" title="Permalink to this heading">#</a></h3>
<p>Various tools and systems implement first-order logic for reasoning and computation. Automated theorem provers and model checkers help in proving the correctness of mathematical theorems or software programs by reasoning about first-order logic statements. Logic programming languages like Prolog are designed around a subset of first-order logic, enabling sophisticated pattern matching and symbolic computation.</p>
<p>First-order logic remains a cornerstone of theoretical computer science, logic, and mathematics, providing a formal basis for understanding and manipulating concepts of truth, proof, and computation.</p>
</section>
</section>
<section id="semantic-networks">
<h2>Semantic networks<a class="headerlink" href="#semantic-networks" title="Permalink to this heading">#</a></h2>
<p>Semantic networks are a type of knowledge representation system used in artificial intelligence (AI) to represent semantic relations among concepts in a network form. They serve as a means to store structured information, enabling computers to process, infer, and understand knowledge in a manner somewhat similar to the way humans do. Semantic networks are widely used in natural language processing, expert systems, and various forms of AI-related tasks such as semantic search, knowledge discovery, and automated reasoning.</p>
<section id="core-elements">
<h3>Core Elements<a class="headerlink" href="#core-elements" title="Permalink to this heading">#</a></h3>
<p>Semantic networks primarily consist of nodes and links:</p>
<ul class="simple">
<li><p><strong>Nodes</strong> represent concepts or instances. Concepts could be abstract (like “Animal”) or concrete (like “Fido”).</p></li>
<li><p><strong>Links (or edges)</strong> represent the relationships between these concepts. These relationships can be varied, such as hierarchical (e.g., “is a” relationships indicating that a dog is a type of animal), associative (e.g., “has a” indicating possession or parts), or casual (e.g., “causes”).</p></li>
</ul>
</section>
<section id="key-characteristics">
<h3>Key Characteristics<a class="headerlink" href="#key-characteristics" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Graph Structure</strong>: Semantic networks are graphically structured, which makes them intuitive and easy for humans to understand and visualize.</p></li>
<li><p><strong>Flexibility</strong>: They can easily incorporate new concepts and relationships, making them adaptable to evolving knowledge bases.</p></li>
<li><p><strong>Inheritance</strong>: They support inheritance, allowing lower-level concepts to inherit properties and relations of higher-level concepts. For example, if “Bird” is connected to “Can Fly” through an “is able to” relation, then all specific instances of birds would inherit this capability unless explicitly stated otherwise (e.g., “Penguin” linked as an exception).</p></li>
<li><p><strong>Reasoning and Inference</strong>: Semantic networks can be used for reasoning and inference, enabling AI systems to derive new knowledge from existing relationships through processes like transitive closure.</p></li>
</ul>
</section>
<section id="id2">
<h3>Applications<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Natural Language Understanding</strong>: Semantic networks can help in understanding the context and relationships in text, aiding in tasks like machine translation, summarization, and semantic search.</p></li>
<li><p><strong>Expert Systems</strong>: They are used in expert systems for encoding expert knowledge in a specific domain, allowing the system to make inferences and provide explanations.</p></li>
<li><p><strong>Knowledge Representation and Management</strong>: Semantic networks are beneficial for organizing large datasets with complex relationships, such as in knowledge graphs (often used by search engines).</p></li>
<li><p><strong>Cognitive Architectures</strong>: They have been used in models aiming to replicate human cognitive capabilities, providing insight into how knowledge might be structured and utilized in the brain.</p></li>
</ul>
</section>
<section id="id3">
<h3>Limitations<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>While powerful, semantic networks have limitations. They may become overly complex with the growth of data, making management and efficient query processing challenging. Moreover, ambiguities in relationships and concepts can arise, requiring careful design and sometimes additional mechanisms (like ontologies) to enforce clarity and consistency.</p>
</section>
<section id="evolution">
<h3>Evolution<a class="headerlink" href="#evolution" title="Permalink to this heading">#</a></h3>
<p>Over time, semantic networks have evolved, integrating with other representations and technologies, such as ontologies in the Semantic Web, to enhance expressiveness and utility. RDF (Resource Description Framework) and OWL (Web Ontology Language) are examples of standards that build upon the idea of semantic networks to enable more sophisticated web content that is machine-readable and capable of supporting advanced data interaction, integration, and reasoning.</p>
</section>
</section>
<section id="frames-and-scripts">
<h2>Frames and scripts<a class="headerlink" href="#frames-and-scripts" title="Permalink to this heading">#</a></h2>
<p>Frames and scripts are two concepts used in artificial intelligence (AI) and cognitive science to represent knowledge about the world. They help AI systems understand and predict the structure of real-world situations, enabling more effective processing of language, reasoning, and decision-making. Both concepts were developed to mimic human cognitive processes in understanding and interacting with the world.</p>
<section id="frames">
<h3>Frames<a class="headerlink" href="#frames" title="Permalink to this heading">#</a></h3>
<p>The concept of frames was introduced by Marvin Minsky in 1974 in his paper “A Framework for Representing Knowledge”. Frames are data structures for representing stereotypical situations. They are like semantic networks or schemas, but more detailed and structured. A frame consists of various slots (attributes or properties) that need to be filled with specific values or pointers to other frames. This structure allows for the representation of complex structured information in a way that is both flexible and efficient.</p>
<p>For example, a “House” frame may have slots for “Owner”, “Address”, “Number of Rooms”, “Color”, etc. Each slot can have default values that can be overridden by specific instances. When a frame is invoked, such as when understanding a story or observing a situation, the AI can use the filled-in values to make inferences or predictions about related aspects of the situation.</p>
</section>
<section id="scripts">
<h3>Scripts<a class="headerlink" href="#scripts" title="Permalink to this heading">#</a></h3>
<p>Scripts were introduced by Roger Schank and Robert P. Abelson in the mid-1970s as a way to represent sequences of events in particular contexts. A script is a structured representation that outlines a sequence of actions or events that are expected to occur in a particular context. Scripts are used by AI systems to predict what happens next in a scenario or to infer missing details.</p>
<p>For example, a “Restaurant” script might include steps such as entering the restaurant, waiting to be seated, reading the menu, ordering food, eating, paying the bill, and leaving. Each step can include roles (e.g., customer, waiter), props (e.g., menu, table), and entry conditions (e.g., the restaurant is open). This enables AIs to understand narratives or dialogues involving restaurants by activating the script and filling it with specific details from the situation.</p>
</section>
<section id="frames-vs-scripts">
<h3>Frames vs. Scripts<a class="headerlink" href="#frames-vs-scripts" title="Permalink to this heading">#</a></h3>
<p>While frames and scripts are related and both deal with structuring knowledge, the main difference lies in their focus and usage. Frames are more general-purpose structures for representing objects, concepts, and situations, including their attributes and relationships. Scripts, on the other hand, are specialized for understanding sequences of events within particular contexts, focusing on temporal relations and roles.</p>
<p>Both frames and scripts are crucial in fields such as natural language processing, understanding stories, and simulating human reasoning in AI. They provide a way to handle the complexity and variability of real-world knowledge, making AI systems more adept at interpreting text, speech, and behaviors in a manner that is closer to human understanding.</p>
</section>
</section>
<section id="ontologies-and-knowledge-graphs">
<h2>Ontologies and knowledge graphs<a class="headerlink" href="#ontologies-and-knowledge-graphs" title="Permalink to this heading">#</a></h2>
<p>Ontologies and knowledge graphs are two fundamental structures for organizing and representing knowledge in a structured form, widely used in the field of artificial intelligence (AI) to enhance machine understanding, reasoning, and information retrieval. Despite their distinct characteristics, they are often used in complementary ways. Below is an overview of each, highlighting their specific features, purposes, and how they intersect.</p>
<section id="ontologies">
<h3>Ontologies<a class="headerlink" href="#ontologies" title="Permalink to this heading">#</a></h3>
<p>An ontology, in the context of AI and computer science, is a formal representation of a set of concepts within a domain and the relationships between those concepts. It is used to reason about the entities within that domain and can be used to describe the domain in a structured, interpretable manner.</p>
<section id="characteristics">
<h4>Characteristics:<a class="headerlink" href="#characteristics" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Formality:</strong> Ontologies are expressed in a formal language, providing precise definitions for the types of relationships and entities they describe.</p></li>
<li><p><strong>Expressiveness:</strong> They are designed to accommodate complex information about categories, properties, and the relations between them.</p></li>
<li><p><strong>Reasoning:</strong> Ontologies facilitate logical inference, enabling machines to deduce new information based on the defined relationships.</p></li>
</ul>
</section>
<section id="purpose">
<h4>Purpose:<a class="headerlink" href="#purpose" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>To provide a comprehensive and explicit conceptual schema within a domain.</p></li>
<li><p>To enable shared understanding and reuse of knowledge across different systems and domains.</p></li>
<li><p>To support semantic interoperability and integration of information from diverse sources.</p></li>
</ul>
</section>
</section>
<section id="knowledge-graphs">
<h3>Knowledge Graphs<a class="headerlink" href="#knowledge-graphs" title="Permalink to this heading">#</a></h3>
<p>Knowledge graphs organize and integrate information into an interconnected network of entities (nodes) and relationships (edges), creating a dynamic way of representing data in a semantic context.</p>
<section id="id4">
<h4>Characteristics:<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Graph-based Structure:</strong> They are represented in a graph format, emphasizing the interconnectivity between entities.</p></li>
<li><p><strong>Semantic Relationships:</strong> Knowledge graphs not only present entities but also describe the rich, typed relationships between these entities.</p></li>
<li><p><strong>Scalability:</strong> They are designed to integrate and synthesize large amounts of data from heterogeneous sources.</p></li>
</ul>
</section>
<section id="id5">
<h4>Purpose:<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>To facilitate semantic searches by leveraging the interconnected nature of data.</p></li>
<li><p>To enhance information retrieval processes through improved data structure and accessibility.</p></li>
<li><p>To support AI applications in understanding and generating human-like responses based on the interconnected data.</p></li>
</ul>
</section>
</section>
<section id="intersections-and-complementary-use">
<h3>Intersections and Complementary Use<a class="headerlink" href="#intersections-and-complementary-use" title="Permalink to this heading">#</a></h3>
<p>Ontologies and knowledge graphs can be closely intertwined. Ontologies often serve as the schema for knowledge graphs, providing the conceptual framework that defines the entities, their attributes, and their interrelationships within the graph. This symbiosis allows knowledge graphs to benefit from the formal structure and reasoning capabilities of ontologies, enhancing the depth and breadth of knowledge representation.</p>
<section id="id6">
<h4>Applications:<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>In semantic web technologies, ontologies underpin RDF (Resource Description Framework) and OWL (Web Ontology Language) standards, which are used to create interoperable web data and knowledge graphs.</p></li>
<li><p>In natural language processing (NLP), they contribute to understanding the context and relationships within text data, enabling more accurate information extraction and text understanding.</p></li>
<li><p>In machine learning, ontologies and knowledge graphs provide rich datasets for training models, as well as frameworks for reasoning and inference, contributing to the development of more intelligent systems.</p></li>
</ul>
<p>In conclusion, both ontologies and knowledge graphs play crucial roles in the organization, representation, and application of knowledge in AI. Their complementary nature allows for the creation of highly structured, interconnected, and semantically rich datasets that drive the development and sophistication of AI technologies.</p>
</section>
</section>
</section>
<section id="rule-based-systems">
<h2>Rule-based systems<a class="headerlink" href="#rule-based-systems" title="Permalink to this heading">#</a></h2>
<p>Rule-based systems, a subset of AI, are a type of software system that apply sets of logical rules to produce outcomes for decision-making or problem-solving processes. These systems are foundational in the field of artificial intelligence and have applications ranging from expert systems in medical diagnosis to business rule engines in financial services.</p>
<section id="components-of-rule-based-systems">
<h3>Components of Rule-Based Systems<a class="headerlink" href="#components-of-rule-based-systems" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Rule Base:</strong> A collection of rules, where each rule is a logical statement that connects conditions with actions or outcomes. Rules are often expressed in an IF-THEN format, where IF part defines the condition and THEN part defines the action.</p></li>
<li><p><strong>Inference Engine:</strong> The core processing unit of a rule-based system that applies logical rules to the known facts in the knowledge base to derive new information or make decisions. The inference engine uses methods such as forward chaining (from facts to conclusions) and backward chaining (from conclusions back to facts) to navigate through the rules.</p></li>
<li><p><strong>Knowledge Base:</strong> Contains the facts or data upon which the rules act. The knowledge base is separate from the rule base but is crucial for the inference engine to operate.</p></li>
<li><p><strong>User Interface:</strong> Allows interaction between the system and its users, enabling the input of data and the display of results.</p></li>
<li><p><strong>Explanation Facility:</strong> Offers explanations about the reasoning process, detailing how the system arrived at a particular conclusion. This is particularly important in expert systems for validation and user trust.</p></li>
</ol>
</section>
<section id="id7">
<h3>Characteristics<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Interpretable:</strong> Rule-based systems are typically easier to understand, modify, and debug compared to some other AI models, such as deep neural networks, because the chain of reasoning is clear and transparent.</p></li>
<li><p><strong>Modular:</strong> New rules can be added without altering the entire system, making these systems relatively flexible when updating or expanding knowledge.</p></li>
<li><p><strong>Deterministic:</strong> Given the same inputs, a rule-based system will always provide the same output, making its behavior predictable.</p></li>
</ul>
</section>
<section id="id8">
<h3>Applications<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Expert Systems:</strong> To mimic the decision-making ability of human experts in specific fields, for example, in medical diagnostics, law, or fault diagnosis.</p></li>
<li><p><strong>Business Rules Management:</strong> Automates and manages decisions in business processes, such as insurance underwriting, loan approval, compliance checking, etc.</p></li>
<li><p><strong>Natural Language Processing:</strong> For grammar checking, language translation, or information extraction where rules are applied to text analysis.</p></li>
<li><p><strong>Control Systems:</strong> Rule-based logic can govern the operation of physical systems, such as in automation or robotics.</p></li>
</ul>
</section>
<section id="challenges-and-limitations">
<h3>Challenges and Limitations<a class="headerlink" href="#challenges-and-limitations" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Scalability:</strong> As the number of rules increases, maintaining and updating the rule base can become complex and unwieldy.</p></li>
<li><p><strong>Flexibility:</strong> Rule-based systems are excellent when the logic is well-defined and unambiguous, but they struggle with nuances, uncertainty, and fuzzy logic which are better handled by probabilistic models and machine learning.</p></li>
<li><p><strong>Dependency on Domain Knowledge:</strong> The effectiveness of a rule-based system is heavily reliant on the quality and comprehensiveness of the rules, which in turn depends on the expertise available during its development.</p></li>
</ul>
<p>In conclusion, rule-based systems are a powerful tool in the AI arsenal, particularly valuable for applications where transparency, consistency, and domain-specific reasoning are paramount. However, their utility in handling complex, uncertain, or highly dynamic environments is limited, often necessitating integration with other AI techniques such as machine learning for optimal performance.</p>
</section>
</section>
<section id="bayesian-networks">
<h2>Bayesian networks<a class="headerlink" href="#bayesian-networks" title="Permalink to this heading">#</a></h2>
<p>Bayesian networks, also known as belief networks, Bayesian Belief Networks (BBNs), or probabilistic directed acyclic graphical models, are a type of probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). They are a powerful tool for expressing and reasoning under uncertainty, making them widely used in various fields such as machine learning, artificial intelligence, bioinformatics, medicine, and more.</p>
<p><strong>Key Concepts and Properties:</strong></p>
<ol class="arabic simple">
<li><p><strong>Nodes and Edges:</strong> In a Bayesian network, each node represents a random variable which can be discrete or continuous. Edges represent conditional dependencies; an edge from node (X) to node (Y) indicates that (Y) depends on (X).</p></li>
<li><p><strong>Conditional Probability Tables (CPTs):</strong> Each node (except those without parents) is associated with a conditional probability table that quantifies the effect of the parents on the node. For a node with no parents, its CPT represents the prior probability of the node.</p></li>
<li><p><strong>Directed Acyclic Graph (DAG):</strong> The graph is acyclic, meaning it has no loops; this allows for the definition of a clear direction in the influence between variables, facilitating the computation of joint probabilities and conditional probabilities.</p></li>
<li><p><strong>Joint Probability Distribution:</strong> One of the key advantages of Bayesian networks is that they compactly represent the joint probability distribution of all the variables in the network. This allows for the calculation of probabilities of interest, such as the probability of certain variables given observed evidence about others.</p></li>
<li><p><strong>Inference:</strong> Bayesian network inference involves computing the posterior distribution of a set of variables given evidence about others. Exact inference algorithms include the junction tree algorithm and variable elimination. Approximate inference methods, like Monte Carlo simulations and variational methods, are often used for large and complex networks.</p></li>
<li><p><strong>Learning:</strong> There are two major aspects to learning in Bayesian networks: parameter learning and structure learning. Parameter learning involves estimating the conditional probability distributions given a fixed network structure and data, often performed via maximum likelihood or Bayesian methods. Structure learning is about discovering the most likely network structure given data, which can be a challenging task due to the combinatorial explosion of possible structures as the number of variables increases.</p></li>
<li><p><strong>Applications:</strong> Bayesian networks are used in a variety of applications such as diagnostic systems in medicine, fault detection in engineering, legal reasoning, risk assessment in finance, and as a tool in genetic research for understanding the probabilistic relations between genes and phenotypic traits.</p></li>
</ol>
<p>Bayesian networks intertwine graph theory, probability theory, and computer science to offer a robust framework for modeling complex systems under uncertainty. Their utility in handling incomplete datasets, integrating prior knowledge, and updating beliefs in light of new evidence makes them an indispensable tool in fields requiring rigorous probabilistic reasoning.</p>
</section>
<section id="knowledge-representation-in-neural-networks">
<h2>Knowledge representation in neural networks<a class="headerlink" href="#knowledge-representation-in-neural-networks" title="Permalink to this heading">#</a></h2>
<p>Knowledge representation in neural networks is a fascinating area of study in the field of artificial intelligence (AI). It involves the methods and mechanisms neural networks use to capture, process, and utilize information. Neural networks, inspired by the biological neural networks in the human brain, are composed of layers of interconnected nodes or neurons, which process information through their connections.</p>
<section id="representing-knowledge-in-neural-networks">
<h3>Representing Knowledge in Neural Networks<a class="headerlink" href="#representing-knowledge-in-neural-networks" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Distributed Representation:</strong> Unlike symbolic AI, where knowledge is represented explicitly with symbols and rules, neural networks use a distributed representation. Information is not stored in a single neuron but is distributed across many neurons. When a neural network learns, the adjustment of weights in the connections between neurons captures the essence of the information presented during training. This means that each piece of knowledge is represented by a pattern of activation across numerous neurons.</p></li>
<li><p><strong>Embeddings:</strong> One common approach to knowledge representation in neural networks, particularly in natural language processing (NLP), is through embeddings. Words, sentences, or even entire documents can be represented as vectors in a high-dimensional space. These vectors capture semantic meaning where the distance and direction between vectors convey the relationship between the entities they represent. For example, word embeddings like Word2Vec or GloVe transform words into vectors such that semantically similar words are positioned closely in vector space.</p></li>
<li><p><strong>Feature Learning:</strong> Neural networks, especially deep learning models, are excellent at automatically discovering and learning the relevant features necessary for a given task. In the context of image recognition, for example, early layers of a convolutional neural network might learn to recognize edges and colors, while deeper layers may identify more complex structures like shapes or even entire objects. This hierarchical organization of knowledge, from simple to complex, mimics how knowledge is structured and abstracted.</p></li>
<li><p><strong>Attention Mechanisms:</strong> More recently, neural networks, notably Transformer architectures, have employed attention mechanisms to dynamically weigh the importance of different parts of the input data. For instance, in a language model, the network can learn to pay more attention to certain words when predicting the next word in a sentence, effectively learning to prioritize or focus on specific pieces of information when making decisions.</p></li>
<li><p><strong>Memory Networks:</strong> Traditional neural networks struggle with long-term dependencies and retaining information over long sequences. Memory networks and variants like Long Short-Term Memory (LSTMs) and the Transformer architecture incorporate mechanisms to store and access information over extended periods. This enables them to represent and utilize knowledge in tasks that require understanding of context or sequences, such as reading comprehension or time-series prediction.</p></li>
</ol>
</section>
<section id="challenges-and-considerations">
<h3>Challenges and Considerations<a class="headerlink" href="#challenges-and-considerations" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Interpretability:</strong> One of the significant challenges with knowledge representation in neural networks is interpretability. Understanding how a neural network has represented knowledge internally can be difficult, leading to the “black box” problem.</p></li>
<li><p><strong>Transfer Learning:</strong> Another consideration is how knowledge learned by a neural network during one task can be transferred and utilized for different, yet related tasks. Transfer learning and multi-task learning are research areas focused on this.</p></li>
</ul>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h3>
<p>Knowledge representation in neural networks is a multi-faceted domain that underpins the model’s ability to learn, reason, and make decisions. As AI research continues to advance, discovering more efficient and interpretable methods of representing knowledge remains a critical objective.</p>
</section>
</section>
<section id="knowledge-representation-and-reasoning-in-natural-language-processing">
<h2>Knowledge representation and reasoning in natural language processing<a class="headerlink" href="#knowledge-representation-and-reasoning-in-natural-language-processing" title="Permalink to this heading">#</a></h2>
<p>Knowledge representation and reasoning (KR&amp;R) are foundational components in the field of artificial intelligence (AI), specifically within the domain of natural language processing (NLP). These components enable machines to understand, interpret, process, and generate human languages in a manner that is both meaningful and contextually relevant. The ultimate goal is for machines to perform tasks involving natural language as competently as humans can, which includes reading text, answering questions, summarizing documents, translating languages, and engaging in conversation.</p>
<section id="knowledge-representation">
<h3>Knowledge Representation<a class="headerlink" href="#knowledge-representation" title="Permalink to this heading">#</a></h3>
<p>In NLP, knowledge representation involves the way information is stored so that a machine can use it to understand natural language. This involves encoding information about the world, concepts, relationships between concepts, rules, and facts in a form that a computer system can process. There are several methods of knowledge representation used in NLP, including:</p>
<ol class="arabic simple">
<li><p><strong>Semantic Networks</strong>: Graph structures for representing knowledge in patterns of interconnected nodes and arcs. They are useful for representing semantic relations between concepts.</p></li>
<li><p><strong>Frame Structures</strong>: Similar to semantic networks but more focused on representing stereotypical situations. Frames are data structures for dividing knowledge into substructures by representing “stereotyped situations.” Think of them as schemas or blueprints for concepts.</p></li>
<li><p><strong>Ontologies</strong>: Formal and explicit specifications of conceptualizations. Ontologies provide a shared and common understanding of a domain that can be communicated between people and application systems.</p></li>
<li><p><strong>Rule-Based Systems</strong>: Represent knowledge in the form of rules that encode expertise in various domains. These rules can be used to infer new knowledge or make decisions.</p></li>
<li><p><strong>Propositional and First-Order Logic</strong>: Represent knowledge in a formal, declarative manner, allowing for rigorous reasoning about the information presented.</p></li>
</ol>
</section>
<section id="reasoning">
<h3>Reasoning<a class="headerlink" href="#reasoning" title="Permalink to this heading">#</a></h3>
<p>Reasoning refers to the process of using the stored knowledge to make inferences, draw conclusions, answer questions, or generate new knowledge. In NLP, reasoning allows systems to understand and generate language that is coherent, context-aware, and relevant to the task at hand. Types of reasoning include:</p>
<ol class="arabic simple">
<li><p><strong>Deductive Reasoning</strong>: Involves applying general rules to specific instances to derive a conclusion. If the premises are true, the conclusion must also be true.</p></li>
<li><p><strong>Inductive Reasoning</strong>: Involves making generalized conclusions from specific instances. These conclusions may have a degree of uncertainty.</p></li>
<li><p><strong>Abductive Reasoning</strong>: Often used in natural language understanding, abductive reasoning involves creating the simplest and most likely explanations for observed phenomena.</p></li>
<li><p><strong>Analogical Reasoning</strong>: Involves drawing parallels between similar situations, often used in problem-solving and decision-making.</p></li>
<li><p><strong>Commonsense Reasoning</strong>: Relates to understanding and making judgments about the everyday world in a way that a typical human would consider “common sense.”</p></li>
</ol>
<p>In NLP, reasoning mechanisms enable systems to undertake tasks like question answering, where the system must understand a user’s query, access relevant knowledge or information, and deduce the most accurate answer. It also allows for more sophisticated dialogue systems that can maintain context and engage in more meaningful conversations with users.</p>
</section>
<section id="challenges">
<h3>Challenges<a class="headerlink" href="#challenges" title="Permalink to this heading">#</a></h3>
<p>Implementing KR&amp;R in NLP faces several challenges, including:</p>
<ul class="simple">
<li><p><strong>Ambiguity Resolution</strong>: Natural language is inherently ambiguous, and interpreting the correct meaning of words, phrases, or sentences based on context can be challenging.</p></li>
<li><p><strong>Scalability</strong>: As the amount of information grows, it becomes increasingly difficult to manage and reason over large knowledge bases.</p></li>
<li><p><strong>Dynamic Knowledge</strong>: Updating knowledge bases to reflect new information or changes in the world remains a constant challenge.</p></li>
<li><p><strong>Commonsense Knowledge</strong>: Encoding and reasoning with the broad and nuanced range of human commonsense knowledge is a significant hurdle.</p></li>
</ul>
<p>Despite these challenges, advancements in machine learning, particularly deep learning, have greatly enhanced the capabilities of NLP systems in knowledge representation and reasoning. By combining traditional symbolic approaches with statistical models, researchers continue to push the boundaries, making systems more effective at understanding and generating human language.</p>
</section>
</section>
<section id="common-sense-reasoning-and-knowledge-bases">
<h2>Common-sense reasoning and knowledge bases<a class="headerlink" href="#common-sense-reasoning-and-knowledge-bases" title="Permalink to this heading">#</a></h2>
<p>Common-sense reasoning and knowledge bases are integral components in the field of Artificial Intelligence (AI), particularly in efforts to endow machines with the ability to understand the world in a way similar to humans. This pursuit involves enabling machines to process, reason with, and act upon information in a manner that mimics human common-sense understanding of everyday situations.</p>
<section id="common-sense-reasoning">
<h3>Common-Sense Reasoning<a class="headerlink" href="#common-sense-reasoning" title="Permalink to this heading">#</a></h3>
<section id="definition">
<h4>Definition<a class="headerlink" href="#definition" title="Permalink to this heading">#</a></h4>
<p>Common-sense reasoning is the type of reasoning involved in everyday human thinking, based on common-sense knowledge. It includes the ability to make assumptions and judgements about the world that seem obvious to humans, such as understanding that ice will melt in the sun, or that people generally prefer to be happy rather than sad. It’s what allows humans to fill in the gaps when information is incomplete, make predictions about the future, and understand nuanced or implied meanings in language.</p>
</section>
<section id="challenges-in-ai">
<h4>Challenges in AI<a class="headerlink" href="#challenges-in-ai" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Ambiguity and Vagueness</strong>: Human language and behavior are full of ambiguity and context-dependent meanings. Machines struggle with this aspect due to their reliance on precise, unambiguous instructions and data.</p></li>
<li><p><strong>Scale and Diversity</strong>: Common-sense knowledge encompasses a vast array of topics and experiences, many of which are implicit and assumed in human communication. Codifying this broad spectrum into a machine-readable format is a monumental task.</p></li>
<li><p><strong>Dynamic Nature</strong>: The world and its interpretations are constantly changing. Keeping a machine’s common-sense knowledge current is a significant challenge.</p></li>
</ul>
</section>
</section>
<section id="knowledge-bases">
<h3>Knowledge Bases<a class="headerlink" href="#knowledge-bases" title="Permalink to this heading">#</a></h3>
<section id="id9">
<h4>Definition<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h4>
<p>A knowledge base in the context of AI is a structured form of information storage that enables the system to access, interpret, and generate information in a meaningful way. It’s a repository of facts about the world, relationships between entities, and rules that govern interactions within a specific domain or more broadly.</p>
</section>
<section id="examples">
<h4>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Cyc</strong>: One of the earliest attempts at creating a comprehensive common-sense knowledge base, aiming to codify general human knowledge and common sense for AI applications.</p></li>
<li><p><strong>ConceptNet</strong>: An open-source project that aims to provide a large-scale semantic graph of common-sense knowledge, useful for language understanding tasks.</p></li>
<li><p><strong>DBpedia and Wikidata</strong>: These knowledge bases are structured from Wikipedia and provide a rich source of factual information that can be used to inform AI algorithms.</p></li>
</ul>
</section>
<section id="id10">
<h4>Challenges<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Completeness and Consistency</strong>: Ensuring that the knowledge base is comprehensive enough to cover a wide range of common-sense knowledge, while also being consistent and free of contradictions, is a significant challenge.</p></li>
<li><p><strong>Updating and Maintenance</strong>: Facts and societal norms change over time, requiring constant updates to the knowledge base to remain relevant and accurate.</p></li>
<li><p><strong>Integration and Utilization</strong>: Creating systems that can effectively integrate and utilize knowledge from the knowledge base in a dynamic, context-sensitive manner remains a complex task.</p></li>
</ul>
</section>
</section>
<section id="connecting-reasoning-and-knowledge-bases">
<h3>Connecting Reasoning and Knowledge Bases<a class="headerlink" href="#connecting-reasoning-and-knowledge-bases" title="Permalink to this heading">#</a></h3>
<p>The ultimate goal in combining common-sense reasoning with knowledge bases is to create AI systems capable of understanding and interacting with the world in a way that is indistinguishable from humans. This involves not only accessing and applying stored knowledge from the knowledge bases but also reasoning about new, unseen situations in a common-sense manner. Advances in machine learning, natural language processing, and knowledge representation are gradually improving our ability to achieve this goal, although much work remains to be done to realize fully common-sense reasoning in AI.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="chap2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 2. Intelligent Agents</p>
      </div>
    </a>
    <a class="right-next"
       href="chap4.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 4. Machine Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#propositional-logic">Propositional logic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-components">Basic Components</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logical-connectives">Logical Connectives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#truth-tables">Truth Tables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations">Limitations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-order-logic">First-order logic</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#core-elements-of-first-order-logic">Core Elements of First-order Logic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#syntax-and-semantics">Syntax and Semantics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-of-first-order-logic">Applications of First-order Logic</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Limitations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-first-order-logic">Tools for First-order Logic</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-networks">Semantic networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#core-elements">Core Elements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-characteristics">Key Characteristics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Limitations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evolution">Evolution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-and-scripts">Frames and scripts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#frames">Frames</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scripts">Scripts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-vs-scripts">Frames vs. Scripts</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ontologies-and-knowledge-graphs">Ontologies and knowledge graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ontologies">Ontologies</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#characteristics">Characteristics:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#purpose">Purpose:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-graphs">Knowledge Graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Characteristics:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Purpose:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intersections-and-complementary-use">Intersections and Complementary Use</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Applications:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rule-based-systems">Rule-based systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#components-of-rule-based-systems">Components of Rule-Based Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Characteristics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-limitations">Challenges and Limitations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-networks">Bayesian networks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-representation-in-neural-networks">Knowledge representation in neural networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#representing-knowledge-in-neural-networks">Representing Knowledge in Neural Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-considerations">Challenges and Considerations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-representation-and-reasoning-in-natural-language-processing">Knowledge representation and reasoning in natural language processing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-representation">Knowledge Representation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reasoning">Reasoning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-sense-reasoning-and-knowledge-bases">Common-sense reasoning and knowledge bases</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-sense-reasoning">Common-Sense Reasoning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definition">Definition</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-in-ai">Challenges in AI</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-bases">Knowledge Bases</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Definition</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">Challenges</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connecting-reasoning-and-knowledge-bases">Connecting Reasoning and Knowledge Bases</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Liang Liu
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>