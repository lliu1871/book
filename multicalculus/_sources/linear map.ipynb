{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1072d540",
   "metadata": {},
   "source": [
    "# Linear maps\n",
    "\n",
    "```{epigraph}\n",
    "*\"Do the difficult things while they are easy and do the great things while they are small. A journey of a thousand miles must begin with a single step.\"*\n",
    "\n",
    "-- Lao Tzu\n",
    "```\n",
    "\n",
    "```{seealso}\n",
    "- [Real number](https://www.britannica.com/science/real-number)\n",
    "- [Real number](https://en.wikipedia.org/wiki/Real_number)\n",
    "```\n",
    "The basic idea of differential calculus is to approximate smooth-but-curved\n",
    "objects by straight lines. With one variable, a smooth function can be approximated by the tangent lines, but with many variables, a linear mapping is described by a matrix. Mechanical matrix manipulations corresponds to the natural ideas\n",
    "of adding, scaling, and composing linear mappings. \n",
    "\n",
    "````{prf:definition} linear mapping\n",
    ":label: linear_mapping\n",
    "The mapping $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ is linear if for all positive integers $k$, all real numbers $\\alpha_1$ through $\\alpha_k$, and all vectors $x_1$ through $x_k$,\n",
    "\n",
    "$$\n",
    "T\\left(\\sum_{i=1}^k \\alpha_i x_i\\right)=\\sum_{i=1}^k \\alpha_i T\\left(x_i\\right)\n",
    "$$\n",
    "````\n",
    "\n",
    "We first consider a special linear map $T: \\mathbb{R}^n\\rightarrow\\mathbb{R}$, called linear functionals, and we show that linear functionals have a special form as described in the following proposition.\n",
    "\n",
    "````{prf:proposition}\n",
    "The linear mappings $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ are precisely the mappings\n",
    "\n",
    "$$\n",
    "T(x)=\\langle a, x\\rangle\n",
    "$$\n",
    "where $a \\in \\mathbb{R}^n$. That is, each linear mapping $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is multiplication by a unique $a \\in \\mathbb{R}^n$ and conversely.\n",
    "````\n",
    "\n",
    "A linear map can be represented as an $m$-tuple of linear maps as described in the following proposition.\n",
    "````{prf:proposition}\n",
    "$T=(T_1,...,T_m):\\mathbb{R}^n\\rightarrow \\mathbb{R}^m$ is linear if and only if each scalar-valued component function $T_i:\\mathbb{R}^n\\rightarrow \\mathbb{R}$ is linear\n",
    "````\n",
    "\n",
    "A linear map is continuous if and only if it is bounded.\n",
    "````{prf:theorem} \n",
    "Let the mapping $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ be linear. Then $T$ is continuous.\n",
    "````\n",
    "\n",
    "The following theorem indicates that linear maps are matrices. \n",
    "````{prf:theorem}\n",
    "Theorem 3.1.7 (Description of Linear Mappings from Vectors to Vectors). The linear mappings $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ are precisely the mappings\n",
    "\n",
    "$$\n",
    "T(x)=Ax\n",
    "$$\n",
    "where $A \\in \\mathrm{M}_{m, n}(\\mathbb{R})$. That is, each linear mapping $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ is multiplication by a unique $A \\in \\mathrm{M}_{m, n}(\\mathbb{R})$ and conversely.\n",
    "````\n",
    "\n",
    "The set of linear maps $L(n,m)$ forms a vector space.\n",
    "\n",
    "````{prf:theorem}\n",
    "Proposition 3.1.8 $\\left(\\mathcal{L}\\left(\\mathbb{R}^n, \\mathbb{R}^m\\right)\\right.$ Forms a Vector Space). Suppose that $S, T: \\mathbb{R}^n \\longrightarrow \\mathbb{R}^m$ are linear and that $a \\in \\mathbb{R}$. Then the mappings\n",
    "\n",
    "$$\n",
    "S+T, a S: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\n",
    "$$\n",
    "are also linear. Consequently, the set of linear mappings from $\\mathbb{R}^n$ to $\\mathbb{R}^m$ forms a vector space.\n",
    "````\n",
    "\n",
    "\n",
    "## Matrix operations\n",
    "The set of matrices with the same dimension is a vector space. Here, we define the vector addition and scalar multiplication for matrices.\n",
    "\n",
    "````{prf:definition} matrix addition\n",
    ":label: matrix_addition\n",
    "Definition 3.2.1 (Matrix Addition).\n",
    "If $A=\\left[a_{i j}\\right]_{m \\times n}$ and $B=\\left[b_{i j}\\right]_{m \\times n}$, then \n",
    "\n",
    "$$A+B=\\left[a_{i j}+b_{i j}\\right]_{m \\times n}$$\n",
    "````\n",
    "\n",
    "````{prf:definition} matrix scalar multiplication\n",
    ":label: matrix_scalar\n",
    "Definition 3.2.2 (Scalar-by-Matrix Multiplication).\n",
    "If $\\alpha \\in \\mathbb{R}$ and $A=\\left[a_{i j}\\right]_{m \\times n}$, then \n",
    "\n",
    "$$\\alpha A=\\left[\\alpha a_{i j}\\right]_{m \\times n}$$\n",
    "````\n",
    "\n",
    "```{note}\n",
    "The set $\\mathrm{M}_{m, n}(\\mathbb{R})$ of $m$-by-$n$ matrices forms a vector space over $\\mathbb{R}$.\n",
    "```\n",
    "\n",
    "Matrix multiplication corresponds to composition of two linear functions.\n",
    "\n",
    "````{prf:definition} matrix multiplication\n",
    ":label: matrix_multiplication\n",
    "Given two matrices $A \\in \\mathrm{M}_{m, n}(\\mathbb{R})$ and $B \\in \\mathrm{M}_{n, p}(\\mathbb{R})$ such that $A$ has as many columns as $B$ has rows, their product, then the product of two matrices $AB \\in \\mathrm{M}_{m, p}(\\mathbb{R})$ has for its $(i, j)^{th}$ entry (for any $i \\in\\{1, \\cdots, m\\}$ and $j \\in\\{1, \\cdots, p\\})$ the inner product of the $i^{th}$ row of $A$ and the $j^{th}$ column of $B$. In symbols,\n",
    "\n",
    "$$\n",
    "(A B)_{i j}=\\langle\\text { ith row of } A, j \\text { th column of } B\\rangle,\n",
    "$$\n",
    "````\n",
    "\n",
    "\n",
    "## Inverse\n",
    "\n",
    "````{prf:theorem} \n",
    ":label: invertibility_matrix_theorem\n",
    "Theorem 3.3.7 (Invertibility and Echelon Form for Matrices). A nonsquare matrix $A$ is never invertible. A square matrix $A$ is invertible if and only if its echelon form is the identity matrix.\n",
    "````\n",
    "\n",
    "When $A$ is square, the discussion above gives an algorithm that simultaneously checks whether it is invertible and finds its inverse when it is.\n",
    "\n",
    "```{admonition} Matrix Inversion Algorithm\n",
    "Given $A \\in \\mathrm{M}_n(\\mathbb{R})$, set up the matrix\n",
    "\n",
    "$$\n",
    "B=\\left[A \\mid I_n\\right]\n",
    "$$\n",
    "in $\\mathrm{M}_{n, 2 n}(\\mathbb{R})$. Carry out row operations on this matrix to reduce the left side to echelon form. If the left side reduces to $I_n$ then $A$ is invertible and the right side is $A^{-1}$. If the left side doesn't reduce to $I_n$ then $A$ is not invertible.\n",
    "```\n",
    "\n",
    "## Determinant\n",
    "````{prf:definition} determinant\n",
    ":label: determinant\n",
    "The determinant is a multilinear skew-symmetric normalized function from the $n$-fold product of $\\mathbb{R}^n$ to $\\mathbb{R}$\n",
    "\n",
    "$$\n",
    "\\operatorname{det}: \\mathbb{R}^n \\times \\cdots \\times \\mathbb{R}^n \\rightarrow \\mathbb{R}\n",
    "$$\n",
    "````\n",
    "\n",
    "The above definition of determinant makes sense only if it exists and unique.\n",
    "\n",
    "````{prf:theorem}\n",
    "The determinant exists and is unique. Furthermore, all multilinear skew-symmetric functions from the $n$-fold product of $\\mathbb{R}^n$ to $\\mathbb{R}$ are scalar multiples of of the determinant. That is, any multilinear skew-symmetric function $\\delta: \\mathbb{R}^n \\times \\cdots \\times \\mathbb{R}^n \\longrightarrow \\mathbb{R}$ is\n",
    "\n",
    "$$\n",
    "\\delta=c \\cdot \\text { det } \\quad \\text { where } c=\\delta\\left(e_1, \\ldots, e_n\\right)\n",
    "$$\n",
    "````\n",
    "The determinant of the product of two matrices is equal to the product of the determinants of two matrices\n",
    "````{prf:theorem}\n",
    "For all matrices $A, B \\in \\mathrm{M}_n(\\mathbb{R})$,\n",
    "\n",
    "$$\n",
    "\\operatorname{det}(A B)=\\operatorname{det}(A) \\operatorname{det}(B) .\n",
    "$$\n",
    "In particular, if $A$ is invertible then the determinant of the matrix inverse is the scalar inverse of the determinant,\n",
    "\n",
    "$$\n",
    "\\operatorname{det}\\left(A^{-1}\\right)=(\\operatorname{det}(A))^{-1} .\n",
    "$$\n",
    "````\n",
    "\n",
    "The following theorem tells us the relationship between determinant and invertibility.\n",
    "````{prf:theorem}\n",
    "Theorem 3.5.6 (Linear Invertibility Theorem). The matrix $A \\in \\mathrm{M}_n(\\mathbb{R})$ is invertible if and only if $\\operatorname{det}(A) \\neq 0$.\n",
    "````\n",
    "\n",
    "The geometric interpretation of a determinant is that the determinant measures the volumn of the parallelepiped formed by the column vectors of the matrix.\n",
    "\n",
    "````{prf:theorem}\n",
    "Theorem 3.8.1 (Geometry of Linear Mappings). Any linear mapping $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ is the composition of a possible squash followed by shears, scales and reflections. If the matrix of $T$ is $A$, then $T$ magnifies volume by $|\\operatorname{det} A|$.\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "source_map": [
   14
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}