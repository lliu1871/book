{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc09f82f",
   "metadata": {},
   "source": [
    "# Chapter 3: Continuous random variables\n",
    "\n",
    "```{epigraph}\n",
    "*\"Do the difficult things while they are easy and do the great things while they are small. A journey of a thousand miles must begin with a single step.\"*\n",
    "\n",
    "-- Lao Tzu\n",
    "```\n",
    "\n",
    "```{seealso}\n",
    "- [Continuous probability distribution](https://en.wikipedia.org/wiki/Probability_distribution#Absolutely_continuous_probability_distribution)\n",
    "```\n",
    "\n",
    "````{prf:definition} cumulative probability function\n",
    ":label: cdf\n",
    "The cumulative distribution function (CDF) of a real-valued random variable $X$, evaluated at $x$, is the probability that $X$ will take a value less than or equal to $x$\n",
    "\n",
    "$$F(x)=P(X \\leq x)$$\n",
    "````\n",
    "- $0\\le F(x)\\le 1$\n",
    "- If $x\\le y$, then $F(x)\\le F(y)$. The CDF is a monotone increasing function  \n",
    "- $\\lim_{x\\rightarrow -\\infty} F(x) = P(X<-\\infty) = 0$\n",
    "- $\\lim_{x\\rightarrow \\infty} F(x) = P(X<\\infty) = 1$\n",
    "\n",
    "````{prf:definition} probability density function\n",
    ":label: pdf\n",
    "The probability density function $f(x)$ is the derivate of the CDF at $x$, i.e.,\n",
    "\n",
    "$$f(x)=\\frac{d F(x)}{d x}$$\n",
    "````\n",
    "\n",
    "- $f(x)\\ge 0$\n",
    "- $F(x)=\\int_{-\\infty}^{x} f(y) d y$\n",
    "- $\\int_{-\\infty}^\\infty f(x)dx = 1$\n",
    "- The probability $P(a<X<b)$ is the area under the density curve $f(x)$ between $a$ and $b$, \n",
    "\n",
    "$$P(a<X<b) = \\int_a^b f(x)dx$$\n",
    "\n",
    "````{prf:definition} expectation\n",
    ":label: expectation2\n",
    "Let $f(x)$ be the density function of a random variable $X$. The expectation of $X$ is defined as\n",
    "\n",
    "$$E(X)=\\int_{-\\infty}^{\\infty} x f(x) d x$$\n",
    "\n",
    "The expectation $E(X)$ is also called the population mean. \n",
    "````\n",
    "\n",
    "Moreover, the expectation of the function $g(X)$ is defined as\n",
    "\n",
    "$$E(g(X))=\\int_{-\\infty}^{\\infty} g(x) f(x) d x$$\n",
    "\n",
    "The variance of $X$ is defined as \n",
    "\n",
    "$$var(X) = E(X-E(X))^2$$\n",
    "\n",
    "- $E(aX+b) = aE(X)+b$\n",
    "- $var(aX+b) = a^2var(x)$\n",
    "\n",
    "## Continuous probability distributions\n",
    "\n",
    "### Uniform distribution\n",
    "\n",
    "- $f(x)=\\frac{1}{b-a}$, for $x \\in[a, b]$\n",
    "- $E(x)=P(X \\leq x)=\\int_{a}^{x} \\frac{1}{(b-a)} d y$\n",
    "- $E(X)=\\int_{a}^{b} x f(x) d x=\\frac{a+b}{2}$\n",
    "- $\\operatorname{var}(X)=E\\left(X^{2}\\right)-\\{E(X)\\}^{2}$\n",
    "\n",
    "### Normal distribution\n",
    "\n",
    "- $f(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} e^{-\\frac{(x-u)^{2}}{2 \\sigma^{2}}}$, for $x \\in[-\\infty, \\infty]$\n",
    "- $E(X)=u$ and $\\operatorname{var}(X)=\\sigma^{2}$\n",
    "\n",
    "If random variable $X$ has the normal distribution with mean $u$ and variance $\\sigma^{2}, Y=aX+b$ follows the normal distribution with mean $a u+b$ and variance $a^{2} \\sigma^{2}$. To calculate the probability, we first standardize the random variable and then use the standard normal distribution to calculate probabilities,\n",
    "\n",
    " $$P(X<d)=P\\left(\\frac{X-u}{\\sigma}<\\frac{d-u}{\\sigma}\\right) = P\\left(Z<\\frac{d-u}{\\sigma}\\right)$$\n",
    "\n",
    "### Exponential distribution\n",
    "\n",
    "- $f(x)=\\frac{1}{\\lambda} e^{-\\frac{x}{\\lambda}}$, for $x>0$ and $\\lambda>0 . F(x)=1-e^{-\\frac{x}{\\lambda}}$\n",
    "- $E(X)=\\lambda$ \n",
    "- $\\operatorname{var}(X)=\\lambda^{2}$\n",
    "\n",
    "### Beta distribution\n",
    "\n",
    "- $f(x)=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}, 0 \\leq x \\leq 1, \\alpha>0, \\beta>0$\n",
    "- $E(X)=\\frac{\\alpha}{\\alpha+\\beta}$\n",
    "- $\\operatorname{var}(X)=\\frac{\\alpha \\beta}{(\\alpha+\\beta)^{2}(\\alpha+\\beta+1)}$\n",
    "\n",
    "### Gamma distribution\n",
    "\n",
    "- $f(x)=\\frac{1}{\\Gamma(\\alpha) \\beta^{\\alpha}} x^{\\alpha-1} e^{-\\frac{x}{\\beta}}, x>0, \\alpha>0, \\beta>0$\n",
    "- $E(X)=\\alpha \\beta$\n",
    "- $\\operatorname{var}(X)=\\alpha \\beta^{2}$ \n",
    "\n",
    "## Transformation\n",
    "\n",
    "Three techniques:\n",
    "\n",
    "(1) CDF: Suppose $Y=g(X)$ and we want to find the probability distribution of Y.\n",
    "\n",
    "$$\n",
    "P(Y \\leq a)=P(g(X) \\leq a)=\\int_{g(x) \\leq a} f(x) d x\n",
    "$$\n",
    "\n",
    "(2) PDF: Suppose that the inverse function $g^{-1}(X)$ exists and is an increasing function.\n",
    "\n",
    "$$\n",
    "P(Y \\leq a)=P(g(X) \\leq a)=P\\left(X \\leq g^{-1}(a)\\right)=F_{X}\\left(g^{-1}(a)\\right)\n",
    "$$\n",
    "\n",
    "Thus, the density function of $Y$ is given by\n",
    "\n",
    "$$\n",
    "f_{Y}(a)=F^{\\prime}{ }_{X}\\left(g^{-1}(a)\\right)=f_{x}\\left(g^{-1}(a)\\right) * \\frac{d g^{-1}(a)}{d a}\n",
    "$$\n",
    "\n",
    "If $g^{-1}(X)$ is a decreasing function, then\n",
    "\n",
    "$$\n",
    "P(Y \\leq a)=P(g(X) \\leq a)=P\\left(X > g^{-1}(a)\\right)=1-F_{X}\\left(g^{-1}(a)\\right)\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "f_{Y}(a)=-F^{\\prime}{ }_{X}\\left(g^{-1}(a)\\right)=-f_{X}\\left(g^{-1}(a)\\right) * \\frac{d g^{-1}(a)}{d a}\n",
    "$$\n",
    "\n",
    "Combining two (increasing or decreasing), we have\n",
    "\n",
    "$$\n",
    "f_{Y}(y)=f_{X}\\left(g^{-1}(y)\\right) *\\left|\\frac{d g^{-1}(y)}{d y}\\right|\n",
    "$$\n",
    "\n",
    "````{prf:example}\n",
    "The random variable $X$ is an exponential random variable with density function $f(x)=\\lambda e^{-\\lambda x}$. Find the distribution of $Y=X+2$. The inverse function is $X=Y-2$. Thus, for $y>2$\n",
    "\n",
    "$$\n",
    "f_{y}(y)=\\lambda e^{-\\lambda(y-2)}\\left|\\frac{d(y-2)}{d y}\\right|=\\lambda e^{-\\lambda(y-2)}\n",
    "$$\n",
    "````\n",
    "\n",
    "(3) MGF: If two random variables $X$ and $Y$ are independent, we can show that\n",
    "\n",
    "$$\n",
    "M_{X+Y}(t)=M_{X}(t) M_{Y}(t)\n",
    "$$\n",
    "\n",
    "````{prf:example}\n",
    "The MGF of a normal random variable is $e^{u t+\\sigma^{2} t^{2} / 2}$. Suppose $X_{1}, X_{2}, \\ldots, X_{n}$ $\\sim \\operatorname{Normal}\\left(u, \\sigma^{2}\\right)$. Find the probability distribution of the sample average $\\frac{\\sum_{i=1}^{n} X_{i}}{n}$. \n",
    "\n",
    "We first find the MGF of the sum $\\sum_{i=1}^{n} X_{i}$, which is equal to\n",
    "\n",
    "$$\n",
    "\\prod_{i=1}^{n} M(t)=e^{n u t+n \\sigma^{2} t^{2} / 2}\n",
    "$$\n",
    "\n",
    "The sum $\\sum_{i=1}^{n} X_{i}$ has a normal distribution with mean $n \\mu$ and variance $n \\sigma^{2}$. \n",
    "\n",
    "Let $Y=\\sum_{i=1}^{n} X_{i}$ and $Z=\\frac{Y}{n}$. Then, \n",
    "\n",
    "$$E\\left(e^{t Z}\\right)=E\\left(e^{\\frac{t Y}{n}}\\right)=e^{u t+\\frac{\\sigma^{2} t^{2}}{2 n}}$$\n",
    " \n",
    "Thus, the sample average $\\frac{1}{n}\\sum_{i=1}^{n} X_{i}$ has a normal distribution with mean $\\mu$ and variance $\\frac{\\sigma^{2}}{n}$.\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "source_map": [
   14
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}