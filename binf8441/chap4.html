
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 4: Multiple random variables &#8212; Statistical Inference in Bioinformatics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Chapter 5: Estimation theory" href="chap5.html" />
    <link rel="prev" title="Chapter 3: Continuous random variables" href="chap3.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Statistical Inference in Bioinformatics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Table of Contents
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Preface
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lecture
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chap0.html">
   Chapter 0: Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap1.html">
   Chapter 1: Probability theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap2.html">
   Chapter 2: Discrete random variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap3.html">
   Chapter 3: Continuous random variables
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Chapter 4: Multiple random variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap5.html">
   Chapter 5: Estimation theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap6.html">
   Chapter 6: Hypothesis testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap7.html">
   Chapter 7: Multiple tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap8.html">
   Chapter 8: RNA-seq analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap9.html">
   Chapter 9: Linear regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap10.html">
   Chapter 10: Monte Carlo simulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap11.html">
   Chapter 11: Bootstrap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap12.html">
   Chapter 12: Bayesian analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap13.html">
   Chapter 13: Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap14.html">
   Chapter 14: Substitution models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chap15.html">
   Chapter 15: Phylogenetic models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lab
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="lab1.html">
   Lab 1: Introduction to R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab2.html">
   Lab 2: Generating random numbers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab3.html">
   Lab 3: The law of large numbers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab4.html">
   Lab 4: GenBank
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab5.html">
   Lab 5: Maixmum Likelihood Estimates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab6.html">
   Lab 6: Hypothesis testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab7.html">
   Lab 7: Multiple tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab8.html">
   Lab 8: RNA-seq analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab9.html">
   Lab 9: Linear regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab10.html">
   Lab 10: Monte Carlo simulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab11.html">
   Lab 11: Bootstrap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab12.html">
   Lab 12: Markov Chain Monte Carlo algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab13.html">
   Lab 13: Markov chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab14.html">
   Lab 14: Substitution models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab15.html">
   Lab 15: Phylogenetic tree reconstruction
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/chap4.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fchap4.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/chap4.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="_sources/chap4.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#discrete-cases">
   Discrete cases
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continuous-cases">
   Continuous cases
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#joint-marginal-conditional-densities">
     Joint, marginal, conditional densities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#joint-probabilities-and-expectations">
     Joint probabilities and expectations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#covariance-and-correlation">
     Covariance and correlation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#independent-random-variables">
   Independent random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sum-of-independent-random-variables">
   The sum of independent random variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Discrete cases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Continuous cases
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mutivariate-probability-distributions">
   Mutivariate probability distributions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multinomial-distribution">
     Multinomial distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multivariate-normal-distribution">
     Multivariate normal distribution
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 4: Multiple random variables</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#discrete-cases">
   Discrete cases
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continuous-cases">
   Continuous cases
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#joint-marginal-conditional-densities">
     Joint, marginal, conditional densities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#joint-probabilities-and-expectations">
     Joint probabilities and expectations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#covariance-and-correlation">
     Covariance and correlation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#independent-random-variables">
   Independent random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sum-of-independent-random-variables">
   The sum of independent random variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Discrete cases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Continuous cases
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mutivariate-probability-distributions">
   Mutivariate probability distributions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multinomial-distribution">
     Multinomial distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multivariate-normal-distribution">
     Multivariate normal distribution
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-4-multiple-random-variables">
<h1>Chapter 4: Multiple random variables<a class="headerlink" href="#chapter-4-multiple-random-variables" title="Permalink to this headline">#</a></h1>
<blockquote class="epigraph">
<div><p><em>“Do the difficult things while they are easy and do the great things while they are small. A journey of a thousand miles must begin with a single step.”</em></p>
<p class="attribution">—Lao Tzu</p>
</div></blockquote>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_random_variable">Multivariate probability distributions</a></p></li>
</ul>
</div>
<section id="discrete-cases">
<h2>Discrete cases<a class="headerlink" href="#discrete-cases" title="Permalink to this headline">#</a></h2>
<p>Considering two discrete random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> with a joint probability mass function (pmf) <span class="math notranslate nohighlight">\(P(X=x, Y=y)\)</span> or simply <span class="math notranslate nohighlight">\(P(x,y)\)</span>.</p>
<div class="proof example admonition" id="4.1">
<p class="admonition-title"><span>Example </span> (4.1)</p>
<section class="example-content" id="proof-content">
<p>The joint pmf can be represented by a table. The following table indicates <span class="math notranslate nohighlight">\(P(X=1,Y=0)=0.1\)</span>, <span class="math notranslate nohighlight">\(P(X=1,Y=1)=0.3\)</span>, <span class="math notranslate nohighlight">\(P(X=2,Y=0)=0.2\)</span>, <span class="math notranslate nohighlight">\(P(X=2,Y=1)=0.4\)</span>. The total probability is <span class="math notranslate nohighlight">\(0.1+0.2+0.3+0.4=1\)</span>.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>X=1</p></th>
<th class="head"><p>X=2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Y=0</p></td>
<td><p>0.1</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>Y=1</p></td>
<td><p>0.3</p></td>
<td><p>0.4</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
</div><div class="proof definition admonition" id="marginal">
<p class="admonition-title"><span>Definition </span> (marginal pmf)</p>
<section class="definition-content" id="proof-content">
<p>The marginal pmf of <span class="math notranslate nohighlight">\(X\)</span> is</p>
<div class="math notranslate nohighlight">
\[
P(X = x)=\sum_{y} P(X=x, Y=y)
\]</div>
</section>
</div><p>The marginal pmf of <span class="math notranslate nohighlight">\(Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
P(y)=\sum_{x} P(x, y)
\]</div>
<p>The conditional probability</p>
<div class="math notranslate nohighlight">
\[
P(x \mid y)=\frac{P(x, y)}{P(y)}
\]</div>
<div class="proof example admonition" id="example-2">
<p class="admonition-title"><span>Example </span></p>
<section class="example-content" id="proof-content">
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>X=1</p></th>
<th class="head"><p>X=2</p></th>
<th class="head"><p>sum</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Y=0</p></td>
<td><p>0.1</p></td>
<td><p>0.2</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-odd"><td><p>Y=1</p></td>
<td><p>0.3</p></td>
<td><p>0.4</p></td>
<td><p>0.7</p></td>
</tr>
<tr class="row-even"><td><p>sum</p></td>
<td><p>0.4</p></td>
<td><p>0.6</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>The conditional probability distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=0\)</span> is <span class="math notranslate nohighlight">\(P(X=1|Y=0) = 0.1/0.3 = 1/3\)</span> and <span class="math notranslate nohighlight">\(P(X=1|Y=0) = 0.2/0.3 = 2/3\)</span></p>
<p>The conditional probability distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=1\)</span> is <span class="math notranslate nohighlight">\(P(X=1|Y=1) = 0.3/0.7 = 3/7\)</span> and <span class="math notranslate nohighlight">\(P(X=1|Y=1) = 0.4/0.7 = 4/7\)</span></p>
</section>
</div><div class="proof definition admonition" id="joint_expectation">
<p class="admonition-title"><span>Definition </span></p>
<section class="definition-content" id="proof-content">
<p>The expectation of a function of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
E(g(x, y))=\sum_{x} \sum_{y} g(x, y) P(x, y)
\]</div>
</section>
</div><p>The conditional expectation of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
E(X \mid Y=y)=\sum_{x} x P(x \mid y)
\]</div>
<div class="proof example admonition" id="4.2">
<p class="admonition-title"><span>Example </span> (4.2)</p>
<section class="example-content" id="proof-content">
<p>The joint pmf of two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is given in the following table</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{|l|l|l|l|l|}
\hline &amp; Y=0 &amp; Y=1 &amp; Y=2 &amp; Y=3 \\
\hline X=1 &amp; 0.1 &amp; 0.1 &amp; 0.1 &amp; 0.2 \\
\hline X=2 &amp; 0.2 &amp; 0.1 &amp; 0.1 &amp; 0.1 \\
\hline
\end{array}
\end{split}\]</div>
<p>The marginal pmf of <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(P(X=1)=0.5\)</span> and <span class="math notranslate nohighlight">\(P(X=2)=0.5\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{|l|l|l|}
\hline x &amp; 1 &amp; 2 \\
\hline p &amp; 0.5 &amp; 0.5\\
\hline
\end{array}
\end{split}\]</div>
<p>The marginal pmf of <span class="math notranslate nohighlight">\(Y\)</span> is <span class="math notranslate nohighlight">\(P(Y=0)=0.3, P(Y=1)=0.2, P(Y=2)=0.2\)</span>, <span class="math notranslate nohighlight">\(P(Y=3)=0.3\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{|l|l|l|l|l|}
\hline y &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\
\hline p &amp; 0.3 &amp; 0.2 &amp; 0.2 &amp; 0.3 \\
\hline
\end{array}
\end{split}\]</div>
<p>The expectation of <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(E(X)=1 * 0.5+2 * 0.5=1.5\)</span></p>
<p>The expectation of <span class="math notranslate nohighlight">\(Y\)</span> is <span class="math notranslate nohighlight">\(E(Y)=0 * 0.3+1 * 0.2+2 * 0.2+3 * 0.3=1.5\)</span></p>
<p>The conditional distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=1\)</span> is <span class="math notranslate nohighlight">\(P(X=1 \mid Y=1)=\frac{1}{3}\)</span> and <span class="math notranslate nohighlight">\(P(X=2 \mid Y=1)=\frac{2}{3}\)</span></p>
<p>The conditional expectation of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=1\)</span> is <span class="math notranslate nohighlight">\(E(X \mid Y=1)=1 * \frac{1}{3}+2 * \frac{2}{3}=\frac{5}{3}\)</span>.</p>
</section>
</div></section>
<section id="continuous-cases">
<h2>Continuous cases<a class="headerlink" href="#continuous-cases" title="Permalink to this headline">#</a></h2>
<section id="joint-marginal-conditional-densities">
<h3>Joint, marginal, conditional densities<a class="headerlink" href="#joint-marginal-conditional-densities" title="Permalink to this headline">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(f(x, y)\)</span> be the joint density function of two continuous random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. The marginal density of <span class="math notranslate nohighlight">\(X\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
f(X=x)=\int_{-\infty}^{\infty} f(x, y) d y
\]</div>
<p>The marginal density of <span class="math notranslate nohighlight">\(Y\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
f(Y=y)=\int_{-\infty}^{\infty} f(x, y) d x
\]</div>
<p>The condition density of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
f(X=x \mid Y=y)=\frac{f(x, y)}{f(y)}
\]</div>
</section>
<section id="joint-probabilities-and-expectations">
<h3>Joint probabilities and expectations<a class="headerlink" href="#joint-probabilities-and-expectations" title="Permalink to this headline">#</a></h3>
<p>We use the double integral to calculate the joint probability <span class="math notranslate nohighlight">\(P(x&lt;a, y&lt;b)\)</span>.</p>
<div class="math notranslate nohighlight">
\[
P(x&lt;a, y&lt;b)=\int_{-\infty}^{a} \int_{-\infty}^{b} f(x, y) d x d y
\]</div>
<p>The expection of a function of random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span></p>
<div class="math notranslate nohighlight">
\[
E(g(x, y))=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x, y) f(x, y) d x d y
\]</div>
<p>The conditional expectation of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
E(X \mid Y=y)=\int_{-\infty}^{\infty} x f(x \mid y) d x
\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Note that <span class="math notranslate nohighlight">\(E(X \mid Y)\)</span> is a function of <span class="math notranslate nohighlight">\(Y\)</span>. Thus, <span class="math notranslate nohighlight">\(E(X \mid Y)\)</span> is a random variable. But <span class="math notranslate nohighlight">\(E(X)\)</span> is a constant. In addition,</p>
<div class="math notranslate nohighlight">
\[
E(X)=E_{Y}(E(X \mid Y))
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\operatorname{var}(X)=\operatorname{var}_{Y}(E(X \mid Y))+E_{Y}(\operatorname{var}(X \mid Y))
\]</div>
</div>
</section>
<section id="covariance-and-correlation">
<h3>Covariance and correlation<a class="headerlink" href="#covariance-and-correlation" title="Permalink to this headline">#</a></h3>
<p>The covariance of <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
\operatorname{cov}(X 1, X 2)=E((X 1-u 1)(X 2-u 2))
\]</div>
<p>When <span class="math notranslate nohighlight">\(X_{1}=X_{2}\)</span>, the covariance of <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> is</p>
<div class="math notranslate nohighlight">
\[
E\left(\left(X_{1}-u_{1}\right)\left(X_{1}-u_{1}\right)\right)=E\left[\left(X_{1}-u_{1}\right)^{2}\right]=\operatorname{var}\left(X_{1}\right)
\]</div>
<ul class="simple">
<li><p>variance is a special case of covariance</p></li>
<li><p>Covariance could be any real number, but variance must be non-negative.</p></li>
</ul>
<p>The correlation of <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\operatorname{corr}(X 1, X 2)=\frac{E((X 1-u 1)(X 2-u 2))}{\sqrt{\operatorname{var}(X 1)} \sqrt{\operatorname{var}(X 2)}}
\]</div>
<ul class="simple">
<li><p>Correlation is the standardized covariance</p></li>
<li><p><span class="math notranslate nohighlight">\(-1 \leq\)</span> correlation <span class="math notranslate nohighlight">\(\leq 1\)</span></p></li>
</ul>
</section>
</section>
<section id="independent-random-variables">
<h2>Independent random variables<a class="headerlink" href="#independent-random-variables" title="Permalink to this headline">#</a></h2>
<p>If two random variables <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> are independent of each other, their joint density function is the product of two marginal densities <span class="math notranslate nohighlight">\(f(X_1)\)</span> and <span class="math notranslate nohighlight">\(f(X_2)\)</span>,</p>
<div class="math notranslate nohighlight">
\[
f\left(X_{1}, X_{2}\right)=f\left(X_{1}\right) f\left(X_{2}\right)
\]</div>
<p>The joint density of <span class="math notranslate nohighlight">\(n\)</span> independent random variables <span class="math notranslate nohighlight">\((X_1,\dots,X_n)\)</span> is the product of <span class="math notranslate nohighlight">\(n\)</span> marginal densities,</p>
<div class="math notranslate nohighlight">
\[
f\left(X_{1},\dots, X_{n}\right)=\prod_{i=1}^nf\left(X_{i}\right)
\]</div>
<div class="proof example admonition" id="4.3">
<p class="admonition-title"><span>Example </span> (4.3)</p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(\left(X_{1}, X_{2}, \ldots, X_{n}\right) \sim \operatorname{Normal}\left(\mu, \sigma^{2}\right)\)</span>. The joint density function of <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split}
f\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n}=x_{n} \mid \mu, \sigma^{2}\right) &amp;= \prod_{i=1}^{n} f\left(X_{i}=x_{i} \mid \mu, \sigma^{2}\right)\\
&amp;= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}} \\
&amp; =\left(\frac{1}{\sqrt{2 \pi \sigma^{2}}}\right)^{n} e^{-\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}
\end{split}
\end{equation}
\end{split}\]</div>
</section>
</div><div class="admonition important">
<p class="admonition-title">Important</p>
<p>The joint density function of data <span class="math notranslate nohighlight">\(\left(X_1,\dots,X_n\right)\)</span> is also called the <strong>likelihood</strong> function. The likelihood function measures the likelihood of the observed data <span class="math notranslate nohighlight">\(\left(X_1,\dots,X_n\right)\)</span> given the parameters. When we estimate the parameter values from data, we choose the parameter values such that they can maximize the likelihood of the observed data; this is called “maximum likelihood estimate”</p>
</div>
<div class="proof example admonition" id="4.4">
<p class="admonition-title"><span>Example </span> (4.4)</p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Poisson}(\lambda)\)</span>. The joint density function is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split}
f\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n} = x_{n} \mid \lambda\right) &amp;=\prod_{i=1}^{n} f\left(X_{i}=x_{i} \mid \lambda\right)\\
 &amp;=\prod_{i=1}^{n} \lambda^{x_{i}} e^{-\lambda} / x_{i} ! \\
&amp; =\lambda^{\sum_{i=1}^{n} x_{i}} e^{-\lambda n} \prod \frac{1}{x_{i}!}
\end{split}
\end{equation}
\end{split}\]</div>
</section>
</div><div class="proof example admonition" id="4.5">
<p class="admonition-title"><span>Example </span> (4.5)</p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Exponential}(\lambda)\)</span>. The joint density function is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split}
f\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n}=x_{n} \mid \lambda\right) &amp;= \prod_{i=1}^{n} f\left(X_{i}=x_{i} \mid \lambda\right)\\
&amp;=\prod_{i=1}^{n} \lambda e^{-\lambda x_{i}}\\
&amp;=(\lambda)^{n} e^{-\lambda \sum_{i=1}^{n} x_{i}}
\end{split}
\end{equation}
\end{split}\]</div>
</section>
</div></section>
<section id="the-sum-of-independent-random-variables">
<h2>The sum of independent random variables<a class="headerlink" href="#the-sum-of-independent-random-variables" title="Permalink to this headline">#</a></h2>
<p>The sum of independent random variables is an important statistic in statistical inference. To understand its statistical properties, it is of great interest to find its probability distribution. Here, we demonstrate an elegant way of deriving the probability distribution of the sum of independent random variables.</p>
<section id="id1">
<h3>Discrete cases<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>Recall that if a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> take values of nonnegative integers, the probability generating function (PGF) of <span class="math notranslate nohighlight">\(X\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
G(t)=E\left(t^{X}\right)=\sum_{x=0}^{\infty} t^{x} p(x)
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>We can find probabilities by differentiating PGF.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{r}
G(t=0)=p(0) \\
G^{\prime}(t=0)=p(1) \\
G^{\prime \prime}(t=0)=p(2)
\end{array}
\end{split}\]</div>
</div>
<p>We can show that</p>
<ol class="simple">
<li><p>The probability generating function for the binomial distribution is <span class="math notranslate nohighlight">\((1-p+pt)^{n}\)</span></p></li>
<li><p>The probability generating function for the Poisson distribution is <span class="math notranslate nohighlight">\(e^{\lambda(t-1)}\)</span></p></li>
</ol>
<div class="proof theorem admonition" id="theorem-8">
<p class="admonition-title"><span class="caption-number">Theorem 5 </span></p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> be independent discrete random variables with the probability generating functions <span class="math notranslate nohighlight">\(G_{1}(t), \ldots, G_{n}(t)\)</span>. Then, the probability generating function of <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
G_{s_{n}}(t)=\prod_{i=1}^{n} G_{i}(t)
\]</div>
</section>
</div><p>If <span class="math notranslate nohighlight">\(X_{1},\ldots, X_{n}\)</span> are identically and independently distributed (iid) with the same probability distribution, then the PGF of their sum is given by</p>
<div class="math notranslate nohighlight">
\[
G_{S_{n}}(t)=(G(t))^{n}
\]</div>
<div class="proof example admonition" id="4.6">
<p class="admonition-title"><span>Example </span> (4.6)</p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Poisson}(\lambda)\)</span> and <span class="math notranslate nohighlight">\(G(t)=e^{\lambda(t-1)}\)</span></p>
<div class="math notranslate nohighlight">
\[
G_{s_{n}}(t)=(G(t))^{n}=e^{n \lambda(t-1)}
\]</div>
<p>Thus, <span class="math notranslate nohighlight">\(S_{n}\)</span> is a Poisson random variable with mean <span class="math notranslate nohighlight">\(\lambda^{*}=n \lambda\)</span>.</p>
</section>
</div><div class="proof example admonition" id="4.7">
<p class="admonition-title"><span>Example </span> (4.7)</p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Bernoulli}(\lambda), G(t)=(1-p)+p t\)</span></p>
<div class="math notranslate nohighlight">
\[
G_{S_{n}}(t)=(G(t))^{n}=(1-p+p t)^{n}
\]</div>
<p>Thus, the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> follows a Binomial distribution with parameters <span class="math notranslate nohighlight">\((n, p)\)</span>.</p>
</section>
</div></section>
<section id="id2">
<h3>Continuous cases<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<p>The PGF cannot be applied to the continuous random variables, because the continuous random variables do not have point probabilities. Instead, we will use the moment generating function to derive the probability distribution of the sum.</p>
<p>Let <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> be independent random variables with moment generating functions <span class="math notranslate nohighlight">\(M_{1}(t), \ldots, M_{n}(t)\)</span>. Then, the moment generating function of <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
M_{S_{n}}(t)=\prod_{i=1}^{n} M_{i}(t)
\]</div>
<p>In addition, if <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> have the same probability distribution, then the MGF of the sum is given by</p>
<div class="math notranslate nohighlight">
\[
M_{S_{n}}(t)=(M(t))^{n}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>We can show that</p>
<ol class="simple">
<li><p>The moment generating function for the normal distribution is <span class="math notranslate nohighlight">\(e^{u t+\sigma^{2} t^{2} / 2}\)</span></p></li>
<li><p>The moment generating function for the exponential distribution is <span class="math notranslate nohighlight">\((1-t / \lambda)^{-1}\)</span></p></li>
<li><p>The moment generating function for the gamma distribution is <span class="math notranslate nohighlight">\((1-t / \alpha)^{-\beta}\)</span></p></li>
</ol>
</div>
<div class="proof example admonition" id="4.8">
<p class="admonition-title"><span>Example </span> (4.8)</p>
<section class="example-content" id="proof-content">
<p>Given a random sample <span class="math notranslate nohighlight">\(X_{1}, \dots, X_{n} \sim \operatorname{Normal}\left(\mu, \sigma^{2}\right)\)</span>, find the probability distribution of the sum <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(X_i's\)</span> have the same normal distribution with the MGF <span class="math notranslate nohighlight">\(M(t)=e^{u t+\sigma^{2} t^{2} / 2}\)</span>, the MGF of the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> is</p>
<div class="math notranslate nohighlight">
\[M_{S_{n}}(t)=(M(t))^{n}=\left(e^{u t+\sigma^{2} t^{2} / 2}\right)^{n}=\left(e^{nut+n\sigma^{2} t^{2} / 2}\right)\]</div>
<p>Thus, the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> follows the normal distribution with mean <span class="math notranslate nohighlight">\(n \mu\)</span> and variance <span class="math notranslate nohighlight">\(n \sigma^{2}\)</span></p>
</section>
</div><div class="proof example admonition" id="4.9">
<p class="admonition-title"><span>Example </span> (4.9)</p>
<section class="example-content" id="proof-content">
<p>Given a random sample <span class="math notranslate nohighlight">\(X_{1}, \dots, X_{n} \sim \exp (\lambda)\)</span>, find the probability distribution of the sum <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(X_i's\)</span> have the same exponential distribution with the MGF <span class="math notranslate nohighlight">\(M(t)=(1-t / \lambda)^{-1}\)</span>, the MGF of the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> is</p>
<div class="math notranslate nohighlight">
\[M_{S_{n}}(t)=(M(t))^{n}=(1-t / \lambda)^{-n}\]</div>
<p>Thus, <span class="math notranslate nohighlight">\(S_{n}\)</span> follows the Gamma distribution with <span class="math notranslate nohighlight">\(\alpha=\lambda\)</span> and <span class="math notranslate nohighlight">\(\beta=n\)</span>.</p>
</section>
</div><p>Alternatively, we may find the CDF of the statistic.</p>
<div class="proof example admonition" id="4.01">
<p class="admonition-title"><span>Example </span> (4.10)</p>
<section class="example-content" id="proof-content">
<p>Find the distribution of <span class="math notranslate nohighlight">\(\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\)</span></p>
<p><span class="math notranslate nohighlight">\(P\left(X_{\max } \leq a\right)=P\left(X_{1} \leq a, X_{2} \leq a, \ldots, X_{n} \leq a\right)=\prod P\left(X_{i} \leq a\right)=(F(a))^{n}\)</span>. Thus, the probability density function is <span class="math notranslate nohighlight">\(f\left(X_{\max }=a\right)=n(F(a))^{n-1} f(a)\)</span></p>
</section>
</div></section>
</section>
<section id="mutivariate-probability-distributions">
<h2>Mutivariate probability distributions<a class="headerlink" href="#mutivariate-probability-distributions" title="Permalink to this headline">#</a></h2>
<section id="multinomial-distribution">
<h3>Multinomial distribution<a class="headerlink" href="#multinomial-distribution" title="Permalink to this headline">#</a></h3>
<p>The multinomial distribution is an extension of the binomial distribution. In the Binomial distribution, there are two possible outcomes. But the multinomial distribution is dealing with multiple <span class="math notranslate nohighlight">\((&gt;2)\)</span> outcomes.</p>
<div class="proof example admonition" id="example-14">
<p class="admonition-title"><span>Example </span></p>
<section class="example-content" id="proof-content">
<p>Suppose the proportions of <span class="math notranslate nohighlight">\(A, C, G, T\)</span> in the genome are <span class="math notranslate nohighlight">\(p_{A}=0.2, p_{c}=0.3, p_{G}=0.2, p_{T}=0.3\)</span>. We select <span class="math notranslate nohighlight">\(n=100\)</span> nucleotides at random from the genome. Let <span class="math notranslate nohighlight">\(X_{A}, X_{C}, X_{G}, X_{T}\)</span> be the number of <span class="math notranslate nohighlight">\(A, C, G, T\)</span>, respectively. <span class="math notranslate nohighlight">\(X_{A}, X_{C}, X_{G}, X_{T}\)</span> are random variables and the sum of <span class="math notranslate nohighlight">\(X_{A}, X_{C}, X_{G}\)</span>, <span class="math notranslate nohighlight">\(X_{T}\)</span> is <span class="math notranslate nohighlight">\(n\)</span>. <span class="math notranslate nohighlight">\(\left\{X_{A}, X_{C}, X_{G}, X_{T}\right\}\)</span> follow the multinomial distribution with joint probability mass function</p>
<div class="math notranslate nohighlight">
\[
P\left(X_{A}=x_{A}, X_{C}=x_{C}, X_{G}=x_{G}, X_{T}=x_{T}\right)=\frac{n !}{x_{A} ! x_{C} ! x_{G} ! x_{T} !}\left(p_{A}\right)^{x_{A}}\left(p_{C}\right)^{x_{C}}\left(p_{G}\right)^{x_{G}}\left(p_{T}\right)^{x_{T}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_{A}+x_{C}+x_{G}+x_{T}=n\)</span> and <span class="math notranslate nohighlight">\(p_{A}+p_{C}+p_{G}+p_{T}=1\)</span></p>
<p>It can be shown that the marginal distribution of <span class="math notranslate nohighlight">\(X_{A}\)</span> is the <span class="math notranslate nohighlight">\(\operatorname{Binomial}\left(n, P_{A}\right)\)</span>. Thus, <span class="math notranslate nohighlight">\(E\left(X_{A}\right)=\)</span> <span class="math notranslate nohighlight">\(nP_{A} = 100*0.2=20\)</span>.</p>
</section>
</div></section>
<section id="multivariate-normal-distribution">
<h3>Multivariate normal distribution<a class="headerlink" href="#multivariate-normal-distribution" title="Permalink to this headline">#</a></h3>
<p>The multivariate normal density function is given by</p>
<div class="math notranslate nohighlight">
\[
f_{\mathbf{x}}\left(x_{1}, \ldots, x_{n}\right)=\frac{1}{\sqrt{(2 \pi)^{k}|\mathbf{\Sigma}|}} \exp \left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{T} \boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\Sigma\)</span> is the covariance matrix and <span class="math notranslate nohighlight">\(\mu\)</span> is the mean vector.</p>
<ul class="simple">
<li><p>The marginal distribution of <span class="math notranslate nohighlight">\(X_{i}\)</span> is normal <span class="math notranslate nohighlight">\(\left(\mu_{i}, \sigma_{i}^{2}\right)\)</span>.</p></li>
<li><p>The conditional distribution of <span class="math notranslate nohighlight">\(X_{i}\)</span> given <span class="math notranslate nohighlight">\(X_{j}\)</span> for <span class="math notranslate nohighlight">\(j \neq i\)</span> is normal</p></li>
<li><p>Any linear combination of <span class="math notranslate nohighlight">\(X_1,\dots, X_n\)</span>, i.e., <span class="math notranslate nohighlight">\(\sum_{i=1}^na_iX_i\)</span> follows the normal distribution with mean <span class="math notranslate nohighlight">\(\sum_{i=1}^na_i\mu_i\)</span> and variance <span class="math notranslate nohighlight">\(a^{t}\Sigma a\)</span> where <span class="math notranslate nohighlight">\(a=(a_1,\dots,a_n)\)</span> and <span class="math notranslate nohighlight">\(a^t\)</span> is the transpose of the vector <span class="math notranslate nohighlight">\(a\)</span>.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="chap3.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Chapter 3: Continuous random variables</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="chap5.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 5: Estimation theory</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Liang Liu<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>