

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 4: Multiple random variables &#8212; Statistical Inference in Bioinformatics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap4';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Chapter 5: Estimation theory" href="chap5.html" />
    <link rel="prev" title="Chapter 3: Continuous random variables" href="chap3.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Table of Contents                              
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preface.html">Preface</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chap0.html">Chapter 0: Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap1.html">Chapter 1: Probability theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap2.html">Chapter 2: Discrete random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap3.html">Chapter 3: Continuous random variables</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Chapter 4: Multiple random variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap5.html">Chapter 5: Estimation theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap6.html">Chapter 6: Hypothesis testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap7.html">Chapter 7: Multiple tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap8.html">Chapter 8: RNA-seq analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap9.html">Chapter 9: Linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap10.html">Chapter 10: Monte Carlo simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap11.html">Chapter 11: Bootstrap</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap12.html">Chapter 12: Bayesian analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap13.html">Chapter 13: Markov Chains</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap14.html">Chapter 14: Substitution models</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap15.html">Chapter 15: Phylogenetic models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lab</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lab1.html">Lab 1: Introduction to R</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab2.html">Lab 2: Generating random numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab3.html">Lab 3: The law of large numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab4.html">Lab 4: BLAST</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab5.html">Lab 5: Optimization algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab6.html">Lab 6: Hypothesis testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab7.html">Lab 7: Multiple tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab8.html">Lab 8: RNA-seq analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab9.html">Lab 9: Linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab10.html">Lab 10: Monte Carlo simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab11.html">Lab 11: Bootstrap</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab12.html">Lab 12: Markov Chain Monte Carlo algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab13.html">Lab 13: Markov chains</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab14.html">Lab 14: Substitution models</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab15.html">Lab 15: Phylogenetic tree reconstruction</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fchap4.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap4.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 4: Multiple random variables</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-cases">Discrete cases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-cases">Continuous cases</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-marginal-conditional-densities">Joint, marginal, conditional densities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-probabilities-and-expectations">Joint probabilities and expectations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-and-correlation">Covariance and correlation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-random-variables">Independent random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sum-of-independent-random-variables">The sum of independent random variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Discrete cases</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Continuous cases</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mutivariate-probability-distributions">Mutivariate probability distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-distribution">Multinomial distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-normal-distribution">Multivariate normal distribution</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-4-multiple-random-variables">
<h1>Chapter 4: Multiple random variables<a class="headerlink" href="#chapter-4-multiple-random-variables" title="Permalink to this heading">#</a></h1>
<blockquote class="epigraph">
<div><p><em>“Do the difficult things while they are easy and do the great things while they are small. A journey of a thousand miles must begin with a single step.”</em></p>
<p class="attribution">—Lao Tzu</p>
</div></blockquote>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_random_variable">Multivariate probability distributions</a></p></li>
</ul>
</div>
<section id="discrete-cases">
<h2>Discrete cases<a class="headerlink" href="#discrete-cases" title="Permalink to this heading">#</a></h2>
<p>Considering two discrete random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> with a joint probability mass function (pmf) <span class="math notranslate nohighlight">\(P(X=x, Y=y)\)</span> or simply <span class="math notranslate nohighlight">\(P(x,y)\)</span>.</p>
<div class="proof example admonition" id="exp4.1">
<p class="admonition-title"><span class="caption-number">Example 30 </span></p>
<section class="example-content" id="proof-content">
<p>The joint pmf can be represented by a table. The following table indicates <span class="math notranslate nohighlight">\(P(X=1,Y=0)=0.1\)</span>, <span class="math notranslate nohighlight">\(P(X=1,Y=1)=0.3\)</span>, <span class="math notranslate nohighlight">\(P(X=2,Y=0)=0.2\)</span>, and <span class="math notranslate nohighlight">\(P(X=2,Y=1)=0.4\)</span>. The total probability is <span class="math notranslate nohighlight">\(0.1+0.2+0.3+0.4=1\)</span>.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>X=1</p></th>
<th class="head"><p>X=2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Y=0</p></td>
<td><p>0.1</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>Y=1</p></td>
<td><p>0.3</p></td>
<td><p>0.4</p></td>
</tr>
</tbody>
</table>
</section>
</div><div class="proof definition admonition" id="def4.1">
<p class="admonition-title"><span class="caption-number">Definition 14 </span> (marginal pmf)</p>
<section class="definition-content" id="proof-content">
<p>The marginal pmf of <span class="math notranslate nohighlight">\(X\)</span> is just the pmf of <span class="math notranslate nohighlight">\(X\)</span>, which can be obtained from the joint pmf by summing over <span class="math notranslate nohighlight">\(Y\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[
P(X = x)=\sum_{y} P(X=x, Y=y)
\]</div>
</section>
</div><p>Similarly, the marginal pmf of <span class="math notranslate nohighlight">\(Y\)</span> can be obtained from the joint pmf by summing over <span class="math notranslate nohighlight">\(X\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[
P(y)=\sum_{x} P(x, y)
\]</div>
<p>Moreover, we can find the conditional probability by the following formula</p>
<div class="math notranslate nohighlight">
\[
P(x \mid y)=\frac{P(x, y)}{P(y)}
\]</div>
<div class="proof example admonition" id="exp4.2">
<p class="admonition-title"><span class="caption-number">Example 31 </span></p>
<section class="example-content" id="proof-content">
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>X=1</p></th>
<th class="head"><p>X=2</p></th>
<th class="head"><p>sum</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Y=0</p></td>
<td><p>0.1</p></td>
<td><p>0.2</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-odd"><td><p>Y=1</p></td>
<td><p>0.3</p></td>
<td><p>0.4</p></td>
<td><p>0.7</p></td>
</tr>
<tr class="row-even"><td><p>sum</p></td>
<td><p>0.4</p></td>
<td><p>0.6</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>The marginal probability distribution of <span class="math notranslate nohighlight">\(X\)</span> is given by</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>X</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>P</p></td>
<td><p>0.4</p></td>
<td><p>0.6</p></td>
</tr>
</tbody>
</table>
<p>The marginal probability distribution of <span class="math notranslate nohighlight">\(Y\)</span> is given by</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Y</p></th>
<th class="head"><p>0</p></th>
<th class="head"><p>1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>P</p></td>
<td><p>0.3</p></td>
<td><p>0.7</p></td>
</tr>
</tbody>
</table>
<p>The conditional probability distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=0\)</span> is <span class="math notranslate nohighlight">\(P(X=1|Y=0) = 0.1/0.3 = 1/3\)</span> and <span class="math notranslate nohighlight">\(P(X=1|Y=0) = 0.2/0.3 = 2/3\)</span></p>
<p>The conditional probability distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=1\)</span> is <span class="math notranslate nohighlight">\(P(X=1|Y=1) = 0.3/0.7 = 3/7\)</span> and <span class="math notranslate nohighlight">\(P(X=1|Y=1) = 0.4/0.7 = 4/7\)</span></p>
<p>In addition, <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are not independent because <span class="math notranslate nohighlight">\(P(X=1, Y=0) \ne P(X=1)P(Y=0)\)</span></p>
</section>
</div><div class="proof definition admonition" id="joint_expectation">
<p class="admonition-title"><span>Definition </span></p>
<section class="definition-content" id="proof-content">
<p>The expectation of a function <span class="math notranslate nohighlight">\(g(x,y)\)</span> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
E(g(x, y))=\sum_{x} \sum_{y} g(x, y) P(x, y)
\]</div>
</section>
</div><p>The conditional expectation of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
E(X \mid Y=y)=\sum_{x} x P(x \mid y)
\]</div>
<div class="proof example admonition" id="exp4.3">
<p class="admonition-title"><span class="caption-number">Example 32 </span></p>
<section class="example-content" id="proof-content">
<p>The joint pmf of two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is given in the following table</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{|l|l|l|l|l|}
\hline &amp; Y=0 &amp; Y=1 &amp; Y=2 &amp; Y=3 \\
\hline X=1 &amp; 0.1 &amp; 0.1 &amp; 0.1 &amp; 0.2 \\
\hline X=2 &amp; 0.2 &amp; 0.1 &amp; 0.1 &amp; 0.1 \\
\hline
\end{array}
\end{split}\]</div>
<p>The marginal pmf of <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(P(X=1)=0.5\)</span> and <span class="math notranslate nohighlight">\(P(X=2)=0.5\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{|l|l|l|}
\hline x &amp; 1 &amp; 2 \\
\hline p &amp; 0.5 &amp; 0.5\\
\hline
\end{array}
\end{split}\]</div>
<p>The marginal pmf of <span class="math notranslate nohighlight">\(Y\)</span> is <span class="math notranslate nohighlight">\(P(Y=0)=0.3, P(Y=1)=0.2, P(Y=2)=0.2\)</span>, <span class="math notranslate nohighlight">\(P(Y=3)=0.3\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{|l|l|l|l|l|}
\hline y &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\
\hline p &amp; 0.3 &amp; 0.2 &amp; 0.2 &amp; 0.3 \\
\hline
\end{array}
\end{split}\]</div>
<p>The expectation of <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(E(X)=1 * 0.5+2 * 0.5=1.5\)</span></p>
<p>The expectation of <span class="math notranslate nohighlight">\(Y\)</span> is <span class="math notranslate nohighlight">\(E(Y)=0 * 0.3+1 * 0.2+2 * 0.2+3 * 0.3=1.5\)</span></p>
<p>The conditional distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=0\)</span> is <span class="math notranslate nohighlight">\(P(X=1 \mid Y=0)=\frac{1}{3}\)</span> and <span class="math notranslate nohighlight">\(P(X=2 \mid Y=0)=\frac{2}{3}\)</span></p>
<p>The conditional expectation of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=0\)</span> is <span class="math notranslate nohighlight">\(E(X \mid Y=0)=1 * \frac{1}{3}+2 * \frac{2}{3}=\frac{5}{3}\)</span>.</p>
</section>
</div></section>
<section id="continuous-cases">
<h2>Continuous cases<a class="headerlink" href="#continuous-cases" title="Permalink to this heading">#</a></h2>
<section id="joint-marginal-conditional-densities">
<h3>Joint, marginal, conditional densities<a class="headerlink" href="#joint-marginal-conditional-densities" title="Permalink to this heading">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(f(x, y)\)</span> be the joint density function of two continuous random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. The marginal density of <span class="math notranslate nohighlight">\(X\)</span> can be obtained from the joint density by integrating over <span class="math notranslate nohighlight">\(Y\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[
f(X=x)=\int_{-\infty}^{\infty} f(x, y) d y
\]</div>
<p>Similarly, the marginal density of <span class="math notranslate nohighlight">\(Y\)</span> can be obtained from the joint density by integrating over <span class="math notranslate nohighlight">\(X\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[
f(Y=y)=\int_{-\infty}^{\infty} f(x, y) dx
\]</div>
<p>The condition density of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
f(X=x \mid Y=y)=\frac{f(x, y)}{f(y)}
\]</div>
</section>
<section id="joint-probabilities-and-expectations">
<h3>Joint probabilities and expectations<a class="headerlink" href="#joint-probabilities-and-expectations" title="Permalink to this heading">#</a></h3>
<p>We use the double integral to calculate the joint probability <span class="math notranslate nohighlight">\(P(x&lt;a, y&lt;b)\)</span>.</p>
<div class="math notranslate nohighlight">
\[
P(x&lt;a, y&lt;b)=\int_{-\infty}^{a} \int_{-\infty}^{b} f(x, y) d x d y
\]</div>
<p>The expection of a function <span class="math notranslate nohighlight">\(g(x,y)\)</span> of random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
E(g(x, y))=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x, y) f(x, y) d x d y
\]</div>
<p>The conditional expectation of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
E(X \mid Y=y)=\int_{-\infty}^{\infty} x f(x \mid y) d x
\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Note that <span class="math notranslate nohighlight">\(E(X \mid Y)\)</span> is a function of <span class="math notranslate nohighlight">\(Y\)</span>. Thus, <span class="math notranslate nohighlight">\(E(X \mid Y)\)</span> is a random variable. But <span class="math notranslate nohighlight">\(E(X)\)</span> is a constant. In addition,</p>
<div class="math notranslate nohighlight">
\[
E(X)=E_{Y}(E(X \mid Y))
\]</div>
<p>This is because</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split}
E_{Y}(E(X \mid Y)) &amp;= \int_{-\infty}^{\infty} (E(X \mid Y) f(y)dy\\
&amp;=\int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} x f(x \mid y) d x\right) f(y)dy\\
&amp;=\int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} x \frac{f(x,y)}{f(y)} d x\right) f(y)dy\\
&amp;=\int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} x f(x,y) d x\right) dy\\
&amp;=\int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} x f(x,y) dy\right) dx\\
&amp;=\int_{-\infty}^{\infty} x \left(\int_{-\infty}^{\infty} f(x,y) dy\right) dx\\
&amp;=\int_{-\infty}^{\infty} xf(x) dx\\
&amp;=E(X)
\end{split}
\end{equation}
\end{split}\]</div>
<p>Similarly, we can show</p>
<div class="math notranslate nohighlight">
\[
\operatorname{var}(X)=\operatorname{var}_{Y}(E(X \mid Y))+E_{Y}(\operatorname{var}(X \mid Y))
\]</div>
</div>
</section>
<section id="covariance-and-correlation">
<h3>Covariance and correlation<a class="headerlink" href="#covariance-and-correlation" title="Permalink to this heading">#</a></h3>
<p>The <strong>covariance</strong> of <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
\operatorname{cov}(X_1, X_2)=E((X_1-u_1)(X_2-u_2))
\]</div>
<p>When <span class="math notranslate nohighlight">\(X_{1}=X_{2}\)</span>, the covariance of <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> is equal to the variance, i.e.,</p>
<div class="math notranslate nohighlight">
\[
E\left(\left(X_{1}-u_{1}\right)\left(X_{1}-u_{1}\right)\right)=E\left[\left(X_{1}-u_{1}\right)^{2}\right]=\operatorname{var}\left(X_{1}\right)
\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<ul class="simple">
<li><p>Variance is a special case of covariance</p></li>
<li><p>Covariance could be any real number, but variance must be non-negative.</p></li>
</ul>
</div>
<p>The correlation of two random variables <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\operatorname{corr}(X_1, X_2)=\frac{E((X_1-u_1)(X_2-u_2))}{\sqrt{\operatorname{var}(X_1)} \sqrt{\operatorname{var}(X_2)}}
\]</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<ul class="simple">
<li><p>Correlation is the standardized covariance</p></li>
<li><p><span class="math notranslate nohighlight">\(-1 \leq\)</span> correlation <span class="math notranslate nohighlight">\(\leq 1\)</span></p></li>
</ul>
</div>
</section>
</section>
<section id="independent-random-variables">
<h2>Independent random variables<a class="headerlink" href="#independent-random-variables" title="Permalink to this heading">#</a></h2>
<p>If two random variables <span class="math notranslate nohighlight">\(X_{1}\)</span> and <span class="math notranslate nohighlight">\(X_{2}\)</span> are independent of each other, their joint density function is the product of two marginal densities <span class="math notranslate nohighlight">\(f(X_1)\)</span> and <span class="math notranslate nohighlight">\(f(X_2)\)</span>,</p>
<div class="math notranslate nohighlight">
\[
f\left(X_{1}, X_{2}\right)=f\left(X_{1}\right) f\left(X_{2}\right)
\]</div>
<p>The joint density of <span class="math notranslate nohighlight">\(n\)</span> independent random variables <span class="math notranslate nohighlight">\((X_1,\dots,X_n)\)</span> is the product of <span class="math notranslate nohighlight">\(n\)</span> marginal densities,</p>
<div class="math notranslate nohighlight">
\[
f\left(X_{1},\dots, X_{n}\right)=\prod_{i=1}^nf\left(X_{i}\right)
\]</div>
<div class="proof example admonition" id="exp4.4">
<p class="admonition-title"><span class="caption-number">Example 33 </span></p>
<section class="example-content" id="proof-content">
<p>The notation <span class="math notranslate nohighlight">\(\left(X_{1}, X_{2}, \ldots, X_{n}\right) \sim \operatorname{Normal}\left(\mu, \sigma^{2}\right)\)</span> indicates that <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> are independently and identically distributed random variables with the same probability distribution <span class="math notranslate nohighlight">\(\operatorname{Normal}\left(\mu, \sigma^{2}\right)\)</span>. The joint density function of <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split}
f\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n}=x_{n} \mid \mu, \sigma^{2}\right) &amp;= \prod_{i=1}^{n} f\left(X_{i}=x_{i} \mid \mu, \sigma^{2}\right)\\
&amp;= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}} \\
&amp; =\left(\frac{1}{\sqrt{2 \pi \sigma^{2}}}\right)^{n} e^{-\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}
\end{split}
\end{equation}
\end{split}\]</div>
</section>
</div><div class="admonition important">
<p class="admonition-title">Important</p>
<p>The joint density function of data <span class="math notranslate nohighlight">\(\left(X_1,\dots,X_n\right)\)</span> is also called the <strong>likelihood</strong> function. The likelihood function measures the likelihood of the observed data <span class="math notranslate nohighlight">\(\left(X_1,\dots,X_n\right)\)</span> given the parameters. When we estimate the parameter values from data, we choose the parameter values such that they can maximize the likelihood of the observed data; this is called “maximum likelihood estimate”</p>
</div>
<div class="proof example admonition" id="exp4.5">
<p class="admonition-title"><span class="caption-number">Example 34 </span></p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Poisson}(\lambda)\)</span>. The joint density function is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split}
f\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n} = x_{n} \mid \lambda\right) &amp;=\prod_{i=1}^{n} f\left(X_{i}=x_{i} \mid \lambda\right)\\
 &amp;=\prod_{i=1}^{n} \lambda^{x_{i}} e^{-\lambda} / x_{i} ! \\
&amp; =\lambda^{\sum_{i=1}^{n} x_{i}} e^{-\lambda n} \prod_{i=1}^n \frac{1}{x_{i}!}
\end{split}
\end{equation}
\end{split}\]</div>
</section>
</div><div class="proof example admonition" id="exp4.6">
<p class="admonition-title"><span class="caption-number">Example 35 </span></p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Exponential}(\lambda)\)</span>. The joint density function is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split}
f\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n}=x_{n} \mid \lambda\right) &amp;= \prod_{i=1}^{n} f\left(X_{i}=x_{i} \mid \lambda\right)\\
&amp;=\prod_{i=1}^{n} \lambda e^{-\lambda x_{i}}\\
&amp;=\lambda^{n} e^{-\lambda \sum_{i=1}^{n} x_{i}}
\end{split}
\end{equation}
\end{split}\]</div>
</section>
</div></section>
<section id="the-sum-of-independent-random-variables">
<h2>The sum of independent random variables<a class="headerlink" href="#the-sum-of-independent-random-variables" title="Permalink to this heading">#</a></h2>
<p>The sum of independent random variables is an important statistic in statistical inference. To understand its statistical properties, it is of great interest to find its probability distribution. Here, we demonstrate an elegant way of deriving the probability distribution of the sum of independent random variables.</p>
<section id="id1">
<h3>Discrete cases<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>Recall that if a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> take values of nonnegative integers, the probability generating function (PGF) of <span class="math notranslate nohighlight">\(X\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
G(t)=E\left(t^{X}\right)=\sum_{x=0}^{\infty} t^{x} p(x)
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>We can find probabilities by differentiating PGF.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{r}
P(X=0)=G(t=0) \\
P(X=1)=G^{\prime}(t=0) \\
P(X=2)=G^{\prime \prime}(t=0)
\end{array}
\end{split}\]</div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The Probability Generating Function (PGF) of a random variable uniquely determines its probability distribution. Once the PGF is determined, the corresponding probability distribution can be identified.</p>
</div>
<p>We can show that</p>
<ol class="arabic simple">
<li><p>The probability generating function for the binomial distribution is <span class="math notranslate nohighlight">\((1-p+pt)^{n}\)</span></p></li>
<li><p>The probability generating function for the Poisson distribution is <span class="math notranslate nohighlight">\(e^{\lambda(t-1)}\)</span></p></li>
</ol>
<div class="proof theorem admonition" id="theorem-8">
<p class="admonition-title"><span class="caption-number">Theorem 11 </span></p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> be independent discrete random variables with the probability generating functions <span class="math notranslate nohighlight">\(G_{1}(t), \ldots, G_{n}(t)\)</span>. Then, the probability generating function of <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span> is equal to the product of individual PGFs, i.e.,</p>
<div class="math notranslate nohighlight">
\[
G_{s_{n}}(t)=\prod_{i=1}^{n} G_{i}(t)
\]</div>
</section>
</div><div class="proof example admonition" id="exp4.7">
<p class="admonition-title"><span class="caption-number">Example 36 </span></p>
<section class="example-content" id="proof-content">
<p>Suppose <span class="math notranslate nohighlight">\(X_{1} \sim Poisson(\lambda_1)\)</span> and <span class="math notranslate nohighlight">\(X_2 \sim Poisson(\lambda_2)\)</span>. Find the probability distribution of <span class="math notranslate nohighlight">\(X_1+X_2\)</span>.</p>
<p>The PGF of <span class="math notranslate nohighlight">\(X_1\)</span> is <span class="math notranslate nohighlight">\(G_{X_1}(t) = e^{\lambda_1(t-1)}\)</span> and the PGF of <span class="math notranslate nohighlight">\(X_2\)</span> is <span class="math notranslate nohighlight">\(G_{X_2}(t) = e^{\lambda_2(t-1)}\)</span>. Thus,</p>
<div class="math notranslate nohighlight">
\[
G_{X_1+X_2}(t)=G_{X_1}(t)G_{X_2}(t)=e^{(\lambda_1+\lambda_2)(t-1)}
\]</div>
<p>This is the PGF of the Poisson distribution with <span class="math notranslate nohighlight">\(\lambda=\lambda_1+\lambda_2\)</span>. Thus, the sum <span class="math notranslate nohighlight">\(X_1+X_2\)</span> is a Poisson random variable with mean <span class="math notranslate nohighlight">\(\lambda=\lambda_1+\lambda_2\)</span>.</p>
</section>
</div><p>If <span class="math notranslate nohighlight">\(X_{1},\ldots, X_{n}\)</span> are identically and independently distributed (iid) with the same probability distribution, then the PGF of their sum is given by</p>
<div class="math notranslate nohighlight">
\[
G_{S_{n}}(t)=(G(t))^{n}
\]</div>
<div class="proof example admonition" id="exp4.8">
<p class="admonition-title"><span class="caption-number">Example 37 </span></p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Poisson}(\lambda)\)</span> and the PGF of the Poisson distribution is <span class="math notranslate nohighlight">\(G(t)=e^{\lambda(t-1)}\)</span>. Then, the PGF of the sum <span class="math notranslate nohighlight">\(S_n=\sum_{i=1}^nX_i\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
G_{s_{n}}(t)=(G(t))^{n}=e^{n \lambda(t-1)}
\]</div>
<p>This is the PGF of the Poisson distribution with <span class="math notranslate nohighlight">\(\lambda^*=n \lambda\)</span>. Thus, <span class="math notranslate nohighlight">\(S_{n}\)</span> of Poisson random variables is again a Poisson random variable with mean <span class="math notranslate nohighlight">\(\lambda^*=n \lambda\)</span>.</p>
</section>
</div><div class="proof example admonition" id="exp4.9">
<p class="admonition-title"><span class="caption-number">Example 38 </span></p>
<section class="example-content" id="proof-content">
<p><span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n} \sim \operatorname{Bernoulli}(p) and the PGF of the Bernoulli distribution is G(t)=(1-p)+p t\)</span>. Then, the PGF of the sum <span class="math notranslate nohighlight">\(S_n=\sum_{i=1}^nX_i\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
G_{S_{n}}(t)=(G(t))^{n}=(1-p+p t)^{n}
\]</div>
<p>This is the PGF of the Binomial distribution.Thus, the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> of Bernoulli random variables is a Binomial random variable.</p>
</section>
</div></section>
<section id="id2">
<h3>Continuous cases<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>The PGF cannot be applied to the continuous random variables, because the continuous random variables do not have point probabilities. Instead, we will use the moment generating function to derive the probability distribution of the sum.</p>
<p>Let <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> be independent random variables with MGFs <span class="math notranslate nohighlight">\(M_{1}(t), \ldots, M_{n}(t)\)</span>. Then, the MGF of the sum <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span> is equal to the product of individual MGFs, i.e.,</p>
<div class="math notranslate nohighlight">
\[
M_{S_{n}}(t)=\prod_{i=1}^{n} M_{i}(t)
\]</div>
<p>In addition, if <span class="math notranslate nohighlight">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> have the same probability distribution, then the MGF of the sum is given by</p>
<div class="math notranslate nohighlight">
\[
M_{S_{n}}(t)=(M(t))^{n}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>We can show that</p>
<ol class="arabic simple">
<li><p>The moment generating function for the normal distribution is <span class="math notranslate nohighlight">\(e^{u t+\sigma^{2} t^{2} / 2}\)</span></p></li>
<li><p>The moment generating function for the exponential distribution is <span class="math notranslate nohighlight">\((1-t / \lambda)^{-1}\)</span></p></li>
<li><p>The moment generating function for the gamma distribution is <span class="math notranslate nohighlight">\((1-t / \alpha)^{-\beta}\)</span></p></li>
</ol>
</div>
<div class="proof example admonition" id="exp4.10">
<p class="admonition-title"><span class="caption-number">Example 39 </span></p>
<section class="example-content" id="proof-content">
<p>Given a random sample <span class="math notranslate nohighlight">\(X_{1}, \dots, X_{n} \sim \operatorname{Normal}\left(\mu, \sigma^{2}\right)\)</span>, find the probability distribution of the sum <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(X_i's\)</span> have the same normal distribution with the MGF <span class="math notranslate nohighlight">\(M(t)=e^{u t+\sigma^{2} t^{2} / 2}\)</span>, the MGF of the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> is</p>
<div class="math notranslate nohighlight">
\[M_{S_{n}}(t)=(M(t))^{n}=\left(e^{u t+\sigma^{2} t^{2} / 2}\right)^{n}=\left(e^{nut+n\sigma^{2} t^{2} / 2}\right)\]</div>
<p>This is the MGF of the normal distribution with mean <span class="math notranslate nohighlight">\(n \mu\)</span> and variance <span class="math notranslate nohighlight">\(n \sigma^{2}\)</span>. Thus, the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> of iid (independently and identically distributed) normal random variables is again a normal random variable with mean <span class="math notranslate nohighlight">\(n \mu\)</span> and variance <span class="math notranslate nohighlight">\(n \sigma^{2}\)</span>.</p>
</section>
</div><div class="proof example admonition" id="exp4.11">
<p class="admonition-title"><span class="caption-number">Example 40 </span></p>
<section class="example-content" id="proof-content">
<p>Given a random sample <span class="math notranslate nohighlight">\(X_{1}, \dots, X_{n} \sim \exp (\lambda)\)</span>, find the probability distribution of the sum <span class="math notranslate nohighlight">\(S_{n}=\sum_{i=1}^{n} X_{i}\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(X_i's\)</span> have the same exponential distribution with the MGF <span class="math notranslate nohighlight">\(M(t)=(1-t / \lambda)^{-1}\)</span>, the MGF of the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> is</p>
<div class="math notranslate nohighlight">
\[M_{S_{n}}(t)=(M(t))^{n}=(1-t / \lambda)^{-n}\]</div>
<p>This is the MGF of the Gamma distribution. Thus, the sum <span class="math notranslate nohighlight">\(S_{n}\)</span> of iid exponential random variables is a Gamma random variable with <span class="math notranslate nohighlight">\(\alpha=\lambda\)</span> and <span class="math notranslate nohighlight">\(\beta=n\)</span>.</p>
</section>
</div><p>Alternatively, the subsequent example illustrates how the Cumulative Distribution Function (CDF) technique can be employed to ascertain the probability distribution of a statistic.</p>
<div class="proof example admonition" id="exp4.12">
<p class="admonition-title"><span class="caption-number">Example 41 </span></p>
<section class="example-content" id="proof-content">
<p>Suppose <span class="math notranslate nohighlight">\(X_{1}, \ldots, X_{n}\)</span> are iid random variables with the same density <span class="math notranslate nohighlight">\(f(x)\)</span> and CDF <span class="math notranslate nohighlight">\(F(x)\)</span>. Find the distribution of <span class="math notranslate nohighlight">\(\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\)</span>.</p>
<p><span class="math notranslate nohighlight">\(P\left(X_{\max } \leq a\right)=P\left(X_{1} \leq a, X_{2} \leq a, \ldots, X_{n} \leq a\right)=\prod P\left(X_{i} \leq a\right)=(F(a))^{n}\)</span>. Thus, the probability density function is <span class="math notranslate nohighlight">\(f\left(X_{\max }=a\right)=n(F(a))^{n-1} f(a)\)</span>.</p>
</section>
</div></section>
</section>
<section id="mutivariate-probability-distributions">
<h2>Mutivariate probability distributions<a class="headerlink" href="#mutivariate-probability-distributions" title="Permalink to this heading">#</a></h2>
<section id="multinomial-distribution">
<h3>Multinomial distribution<a class="headerlink" href="#multinomial-distribution" title="Permalink to this heading">#</a></h3>
<p>The multinomial distribution is an extension of the binomial distribution. In the Binomial distribution, there are two possible outcomes. The multinomial distribution is dealing with multiple <span class="math notranslate nohighlight">\((&gt;2)\)</span> outcomes.</p>
<div class="proof example admonition" id="exp4.13">
<p class="admonition-title"><span class="caption-number">Example 42 </span></p>
<section class="example-content" id="proof-content">
<p>Suppose the proportions of <span class="math notranslate nohighlight">\(A, C, G, T\)</span> in the genome are <span class="math notranslate nohighlight">\(p_{A}=0.2, p_{c}=0.3, p_{G}=0.2, p_{T}=0.3\)</span>. We select <span class="math notranslate nohighlight">\(n=100\)</span> nucleotides at random from the genome. Let <span class="math notranslate nohighlight">\(X_{A}, X_{C}, X_{G}, X_{T}\)</span> be the number of <span class="math notranslate nohighlight">\(A, C, G, T\)</span>, respectively. <span class="math notranslate nohighlight">\(X_{A}, X_{C}, X_{G}, X_{T}\)</span> are random variables and the sum of <span class="math notranslate nohighlight">\(X_{A}, X_{C}, X_{G}\)</span>, <span class="math notranslate nohighlight">\(X_{T}\)</span> is <span class="math notranslate nohighlight">\(n\)</span>. <span class="math notranslate nohighlight">\(\left\{X_{A}, X_{C}, X_{G}, X_{T}\right\}\)</span> follow the multinomial distribution with joint probability mass function</p>
<div class="math notranslate nohighlight">
\[
P\left(X_{A}=x_{A}, X_{C}=x_{C}, X_{G}=x_{G}, X_{T}=x_{T}\right)=\frac{n !}{x_{A} ! x_{C} ! x_{G} ! x_{T} !}\left(p_{A}\right)^{x_{A}}\left(p_{C}\right)^{x_{C}}\left(p_{G}\right)^{x_{G}}\left(p_{T}\right)^{x_{T}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_{A}+x_{C}+x_{G}+x_{T}=n\)</span> and <span class="math notranslate nohighlight">\(p_{A}+p_{C}+p_{G}+p_{T}=1\)</span></p>
<p>It can be shown that the marginal distribution of <span class="math notranslate nohighlight">\(X_{A}\)</span> is the <span class="math notranslate nohighlight">\(\operatorname{Binomial}\left(n, P_{A}\right)\)</span>. Thus, <span class="math notranslate nohighlight">\(E\left(X_{A}\right)=\)</span> <span class="math notranslate nohighlight">\(nP_{A} = 100*0.2=20\)</span>.</p>
</section>
</div></section>
<section id="multivariate-normal-distribution">
<h3>Multivariate normal distribution<a class="headerlink" href="#multivariate-normal-distribution" title="Permalink to this heading">#</a></h3>
<p>The multivariate normal density function is given by</p>
<div class="math notranslate nohighlight">
\[
f_{\mathbf{x}}\left(x_{1}, \ldots, x_{n}\right)=\frac{1}{\sqrt{(2 \pi)^{k}|\mathbf{\Sigma}|}} \exp \left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{T} \boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\Sigma\)</span> is the covariance matrix and <span class="math notranslate nohighlight">\(\mu\)</span> is the mean vector.</p>
<ul class="simple">
<li><p>The marginal distribution of <span class="math notranslate nohighlight">\(X_{i}\)</span> is normal <span class="math notranslate nohighlight">\(\left(\mu_{i}, \sigma_{i}^{2}\right)\)</span>.</p></li>
<li><p>The conditional distribution of <span class="math notranslate nohighlight">\(X_{i}\)</span> given <span class="math notranslate nohighlight">\(X_{j}\)</span> for <span class="math notranslate nohighlight">\(j \neq i\)</span> is normal</p></li>
<li><p>Any linear combination of <span class="math notranslate nohighlight">\(X_1,\dots, X_n\)</span>, i.e., <span class="math notranslate nohighlight">\(\sum_{i=1}^na_iX_i\)</span> follows the normal distribution with mean <span class="math notranslate nohighlight">\(\sum_{i=1}^na_i\mu_i\)</span> and variance <span class="math notranslate nohighlight">\(a^{t}\Sigma a\)</span> where <span class="math notranslate nohighlight">\(a=(a_1,\dots,a_n)\)</span> and <span class="math notranslate nohighlight">\(a^t\)</span> is the transpose of the vector <span class="math notranslate nohighlight">\(a\)</span>.</p></li>
</ul>
<div class="proof example admonition" id="exp4.14">
<p class="admonition-title"><span class="caption-number">Example 43 </span></p>
<section class="example-content" id="proof-content">
<p>Suppose three random variables <span class="math notranslate nohighlight">\((X_1, X_2, X_3)\)</span> follow a Multivariate normal distribution with the mean vector <span class="math notranslate nohighlight">\(\mu=(1.2, 3.4, 0.4)\)</span> and the covariance matrix <span class="math notranslate nohighlight">\(\begin{pmatrix} 0.1&amp;   0.2&amp;  -0.4\\ 0.2 &amp;     1.3 &amp;    1.8\\ -0.4 &amp;   1.8  &amp;  1.1\end{pmatrix}\)</span>.</p>
<p>a) What is the probability density function of <span class="math notranslate nohighlight">\(X_1\)</span>?<br />
<span class="math notranslate nohighlight">\(E(X_1) = 1.2\)</span> and <span class="math notranslate nohighlight">\(var(X_1)=0.1\)</span>. Thus, <span class="math notranslate nohighlight">\(X_1\)</span> follows <span class="math notranslate nohighlight">\(Normal(1.2, 0.1)\)</span>.</p>
<p>b) Find <span class="math notranslate nohighlight">\(E(X_2)\)</span> and <span class="math notranslate nohighlight">\(var(X_3)\)</span> <br />
<span class="math notranslate nohighlight">\(E(X_2) = 3.4\)</span> and <span class="math notranslate nohighlight">\(var(X_3) = 1.1\)</span></p>
<p>c) Find <span class="math notranslate nohighlight">\(E(2X_1-X_2-4X_3)\)</span> and <span class="math notranslate nohighlight">\(var(X_1+X_2+X_3)\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split} 
E(2X_1-X_2-4X_3) &amp;= 2E(X_1)-E(X_2)-4E(X_3) \\
&amp;=2*1.2-3.4-4*0.4 \\
&amp;=-2.6
\end{split}
\end{equation}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
\begin{split} 
var(X_1+X_2+X_3) &amp;= var(X_1)+var(X_2)+var(X_3)+2cov(X_1,X_2)+2cov(X_1,X_3)+2cov(X_2,X_3) \\
&amp;=0.1+1.3+1.1+2*0.2+2*(-0.4)+2*1.8 \\
&amp;=3.7
\end{split}
\end{equation}
\end{split}\]</div>
<p>d) Let <span class="math notranslate nohighlight">\(Y = X_1+X_2+X_3\)</span>. Find the probability density function of <span class="math notranslate nohighlight">\(Y\)</span>   <br />
<span class="math notranslate nohighlight">\(E(X_1+X_2+X_3)=1.2+3.4+0.4=5\)</span> and <span class="math notranslate nohighlight">\(var(X_1+X_2+X_3) = 3.7\)</span>. Thus, <span class="math notranslate nohighlight">\(Y\)</span> follows <span class="math notranslate nohighlight">\(Normal(5, 3.7)\)</span>.</p>
</section>
</div></section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="chap3.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 3: Continuous random variables</p>
      </div>
    </a>
    <a class="right-next"
       href="chap5.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 5: Estimation theory</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-cases">Discrete cases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-cases">Continuous cases</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-marginal-conditional-densities">Joint, marginal, conditional densities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-probabilities-and-expectations">Joint probabilities and expectations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-and-correlation">Covariance and correlation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-random-variables">Independent random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sum-of-independent-random-variables">The sum of independent random variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Discrete cases</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Continuous cases</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mutivariate-probability-distributions">Mutivariate probability distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-distribution">Multinomial distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-normal-distribution">Multivariate normal distribution</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Liang Liu
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>